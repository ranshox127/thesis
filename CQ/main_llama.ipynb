{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# 取得專案根目錄 (lib 的父目錄)\n",
    "root_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# 將 lib 加入 Python 模組搜尋路徑\n",
    "sys.path.append(os.path.join(root_dir, \"lib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Optional\n",
    "import json\n",
    "\n",
    "\n",
    "class Node(TypedDict):\n",
    "    node_id: str\n",
    "    question: str\n",
    "    annotation: str\n",
    "\n",
    "\n",
    "class Edge(TypedDict):\n",
    "    start: str\n",
    "    end: str\n",
    "    annotation: str\n",
    "\n",
    "\n",
    "class Q_DAG:\n",
    "    def __init__(self):\n",
    "        self.nodes: List[Node] = []\n",
    "        self.edges: List[Edge] = []\n",
    "\n",
    "    def add_root(self, question: str) -> None:\n",
    "        root_node = Node(node_id=\"Q\", question=question, annotation=\"\")\n",
    "        self.nodes.append(root_node)\n",
    "\n",
    "    def get_node_question(self, node_id: str) -> Optional[Node]:\n",
    "        for node in self.nodes:\n",
    "            if node[\"node_id\"] == node_id:\n",
    "                return node[\"question\"]\n",
    "        return None\n",
    "\n",
    "    def derive_question(self, new_sub_question: str, edge_annotation: str, parent_id: str) -> tuple[str, str]:\n",
    "        \"\"\"\n",
    "        根據 parent_id，派生出一個新的子節點（question）。\n",
    "        - 自動產生子節點 id，格式為 Q.1、Q.1.1 等（依據 parent_id）。\n",
    "        - 如果該子問題已存在，就不重複建立節點，但可以重複建立「新的父邊」。\n",
    "        - 檢查是否已有相同的邊；如果有就跳過。\n",
    "        - 檢查是否會造成循環（違反 DAG）。\n",
    "\n",
    "        回傳子節點 id（不論新建或重用）。\n",
    "        \"\"\"\n",
    "        existing_ids = {node[\"node_id\"] for node in self.nodes}\n",
    "        parent_ids = {node[\"node_id\"] for node in self.nodes}\n",
    "\n",
    "        # 檢查 parent_id 是否存在\n",
    "        if parent_id not in parent_ids:\n",
    "            raise ValueError(f\"Parent node '{parent_id}' does not exist.\")\n",
    "\n",
    "        # 想添加的子問題是否存在\n",
    "        existing_node_id = None\n",
    "        for node in self.nodes:\n",
    "            if self._normalize(node[\"question\"]) == self._normalize(new_sub_question):\n",
    "                existing_node_id = node[\"node_id\"]\n",
    "                break\n",
    "\n",
    "        # 若子問題不存在，則建立新節點\n",
    "        if existing_node_id is None:\n",
    "            # 完全新節點，可直接加入，不需 cycle 檢查\n",
    "            base = parent_id\n",
    "            i = 1\n",
    "            while True:\n",
    "                new_id = f\"{base}.{i}\"\n",
    "                if new_id not in existing_ids:\n",
    "                    break\n",
    "                i += 1\n",
    "\n",
    "            self.nodes.append(\n",
    "                Node(node_id=new_id, question=new_sub_question, annotation=\"\"))\n",
    "            self.edges.append(\n",
    "                Edge(start=parent_id, end=new_id, annotation=edge_annotation))\n",
    "            return new_id, \"new node added\"\n",
    "\n",
    "        # 如果子問題已存在，則使用現有的 ID\n",
    "        else:\n",
    "            new_id = existing_node_id\n",
    "            # 檢查是否已有這條邊\n",
    "            for edge in self.edges:\n",
    "                if edge[\"start\"] == parent_id and edge[\"end\"] == new_id:\n",
    "                    raise ValueError(\n",
    "                        f\"Edge from '{parent_id}' to '{new_id}' already exists.\")\n",
    "\n",
    "            # 子節點已存在，需檢查加入這條邊會不會形成環\n",
    "            temp_edges = self.edges + \\\n",
    "                [Edge(start=parent_id, end=new_id, annotation=edge_annotation)]\n",
    "            if self._has_cycle(temp_edges):\n",
    "                raise ValueError(\n",
    "                    f\"Adding edge from '{parent_id}' to '{new_id}' would create a cycle.\")\n",
    "\n",
    "            self.edges.append(\n",
    "                Edge(start=parent_id, end=new_id, annotation=edge_annotation))\n",
    "            return new_id, \"new edge added\"\n",
    "\n",
    "    def _has_cycle(self, edges: List[Edge]) -> bool:\n",
    "        \"\"\"簡單的 DFS 來偵測是否有循環。\"\"\"\n",
    "\n",
    "        from collections import defaultdict, deque\n",
    "\n",
    "        graph = defaultdict(list)\n",
    "        for edge in edges:\n",
    "            graph[edge[\"start\"]].append(edge[\"end\"])\n",
    "\n",
    "        visited = set()\n",
    "        in_path = set()\n",
    "\n",
    "        def dfs(node):\n",
    "            if node in in_path:\n",
    "                return True\n",
    "            if node in visited:\n",
    "                return False\n",
    "            visited.add(node)\n",
    "            in_path.add(node)\n",
    "            for neighbor in graph.get(node, []):\n",
    "                if dfs(neighbor):\n",
    "                    return True\n",
    "            in_path.remove(node)\n",
    "            return False\n",
    "\n",
    "        for node in graph:\n",
    "            if dfs(node):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def _normalize(self, q: str) -> str:\n",
    "        return q.lower().strip().rstrip(\"?。！？\")\n",
    "\n",
    "    def update_node(self, node_id: str, new_annotation: str) -> None:\n",
    "        \"\"\"\n",
    "        根據 node_id 更新該節點的 annotation。\n",
    "        - 檢查 node_id 是否存在。\n",
    "        \"\"\"\n",
    "        for node in self.nodes:\n",
    "            if node[\"node_id\"] == node_id:\n",
    "                node[\"annotation\"] = new_annotation\n",
    "                return\n",
    "\n",
    "        raise ValueError(f\"Node with id '{node_id}' not found.\")\n",
    "\n",
    "    def export_DAG(self) -> str:\n",
    "        \"\"\"\n",
    "        將目前 DAG（nodes 與 edges）以 dict 形式包裝並轉為 JSON 字串。\n",
    "        回傳格式：\n",
    "        {\n",
    "            \"nodes\": [...],\n",
    "            \"edges\": [...]\n",
    "        }\n",
    "        \"\"\"\n",
    "        dag_dict = {\n",
    "            \"nodes\": self.nodes,\n",
    "            \"edges\": self.edges\n",
    "        }\n",
    "        return json.dumps(dag_dict, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_llama import Agent_llama\n",
    "from tools import search\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# 1247 tokens\n",
    "planner_system_prompt = \"\"\"You are a Planner Agent designed to reason through complex, open-ended, or ambiguous questions by constructing, reflecting on, and expanding a directed acyclic graph (DAG) of interrelated sub-questions. Your task is not simply to retrieve answers, but to actively explore the question space, refine your understanding, and make informed decisions about when the original question has been sufficiently addressed.\n",
    "\n",
    "---\n",
    "\n",
    "## Problem Space Representation: The Question DAG\n",
    "\n",
    "The DAG is your evolving internal model of the problem. It represents your reasoning process — how the main question relates to sub-questions, intermediate knowledge, and reflections.\n",
    "Each node contains:\n",
    "- `node_id`: a unique identifier\n",
    "- `question`: a sub-question or original question\n",
    "- `annotation`: your current thoughts, insights, summaries, or hypotheses about that question\n",
    "\n",
    "Each annotation helps build and maintain your internal representation of the problem. For example:\n",
    "- A node’s `annotation` may include:\n",
    "  - A summary of what you currently understand about the question\n",
    "  - A hypothesis or assumption you are testing\n",
    "  - A brief note on what you still need to find out\n",
    "- An `edge_annotation` should briefly explain how the sub-question contributes to answering the parent question — e.g., cause-effect, component, condition, clarification, definition, comparison, or implication.\n",
    "---\n",
    "\n",
    "## Input Format\n",
    "\n",
    "You are always shown the current DAG in JSON format, including all nodes and edges, representing the most up-to-date state of your reasoning process.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Reasoning Guidelines\n",
    "\n",
    "- You cannot delete nodes or edges. Even if a previous path turns out to be incorrect or irrelevant, leave it intact and revise your understanding through `update()`. This mimics how humans preserve earlier lines of thought for traceability, reflection, and learning from missteps.\n",
    "- You are encouraged to **revisit and revise** previous thoughts using `update`, especially as new information or sub-answers emerge.\n",
    "- When decomposing, focus on asking the right questions — use logical, causal, definitional, or investigative angles that deepen your understanding.\n",
    "- When unsure or the question is broad, **start by clarifying or framing the problem**, not jumping to answers.\n",
    "- For vague or ill-defined questions, take initiative to deconstruct ambiguity, identify what is missing, and reframe as needed. You shape the problem space.\n",
    "\n",
    "---\n",
    "\n",
    "## Your Tools\n",
    "\n",
    "You have three core actions to build and navigate the problem space:\n",
    "\n",
    "1. **question_decompose**\n",
    "   Use this to break down a question node into one or more meaningful sub-questions.\n",
    "   - You may decompose multiple nodes at once.\n",
    "   - Specify `parent_question_id`, `sub_question`, and an `edge_annotation` explaining the logical or conceptual relationship.\n",
    "   - Multiple parents pointing to the same sub-question are allowed.\n",
    "   - Keep the graph acyclic.\n",
    "\n",
    "   Example:\n",
    "   ```json\n",
    "   {\n",
    "     \"graph\": [\n",
    "       {\n",
    "         \"parent_question_id\": \"Q\",\n",
    "         \"sub_question\": \"How has telework affected work-life boundaries?\",\n",
    "         \"edge_annotation\": \"Understanding personal impact helps assess broader social shifts.\"\n",
    "       },\n",
    "       {\n",
    "         \"parent_question_id\": \"Q.1\",\n",
    "         \"sub_question\": \"Does telework reinforce or reduce social inequality?\",\n",
    "         \"edge_annotation\": \"Social impact includes distributional effects across groups.\"\n",
    "       }\n",
    "     ]\n",
    "   }\n",
    "    ```\n",
    "\n",
    "2.  **update**\n",
    "    Use this to revise or expand the annotation of existing nodes.\n",
    "    - This reflects new insights, summaries, clarifications, or changes in understanding.\n",
    "    - You are encouraged to use this tool to reflect, correct, or reframe — especially after learning something new.\n",
    "    - This is a key part of your **metacognitive behavior** — thinking about your thinking.\n",
    "    \n",
    "    Example:\n",
    "    ```json\n",
    "    {\n",
    "      \"nodes\": [\n",
    "        {\n",
    "          \"question_id\": \"Q.1\",\n",
    "          \"new_annotation\": \"Workers report blurred boundaries between home and work, leading to both flexibility and stress.\"\n",
    "        },\n",
    "        {\n",
    "          \"question_id\": \"Q.2\",\n",
    "          \"new_annotation\": \"Emerging evidence suggests that higher-income workers benefit more from telework options, widening inequality.\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "    ```\n",
    "\n",
    "3.  **final_answer**\n",
    "    Use this only when you believe the original question has been sufficiently addressed **given the available steps so far**.  \n",
    "    You do not need perfect certainty — you must simply provide a reason why the current DAG gives you enough understanding to form a meaningful answer.\n",
    "    - Provide a justification explaining why you believe your DAG now contains enough understanding.\n",
    "    - Your answer should be clear, comprehensive, and informative—sufficient in length to convey key insights.\n",
    "    - You may use paragraph or bullet point format as appropriate.\n",
    "    - Aim to include key aspects uncovered in the DAG — such as causes, mechanisms, consequences, or trade-offs — without repeating every detail.\n",
    "    \n",
    "    Example:\n",
    "    ```json\n",
    "    {\n",
    "      \"reason\": \"The sub-questions cover key social dimensions — lifestyle, geography, and inequality — and their annotations provide sufficient insight.\",\n",
    "    }\n",
    "    ```\n",
    "\n",
    "---\n",
    "\n",
    "## Metacognitive Expectations\n",
    "\n",
    "This is not a static search task — it is an evolving thinking process.\n",
    "\n",
    "- Use `update()` to **reflect**, summarize new insights, question assumptions, or refine your current framing.\n",
    "- Use `question_decompose()` to **expand the problem space**, identify what needs to be known, or clarify uncertainty.\n",
    "- Use `final_answer()` only when your internal model (the DAG) gives you enough confidence that you can answer well.\n",
    "- At each step, treat the DAG as your evolving internal model of understanding — be thoughtful about how you build it.\n",
    "\n",
    "- When starting from a single root question with no sub-questions yet, you may choose to either:\n",
    "  - Use `update()` to record your initial thoughts, assumptions, or possible lines of inquiry, or\n",
    "  - Use `question_decompose()` to begin breaking down the problem into more specific components.\n",
    "There is no fixed preference — use your best judgment based on the question’s clarity and complexity.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CQ_Solver_llama:\n",
    "    def __init__(self, llm, system_prompt, max_turns=9, debug_log=\"llama_debug.log\", summary_json=\"llama_summary.json\"):\n",
    "        self.planner = Agent_llama(llm=llm)\n",
    "        self.searcher = Agent_llama(llm=llm)\n",
    "        self.max_turns = max_turns\n",
    "        self.planner_conversation = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt}]\n",
    "        self.conversation_log = []  # 用於詳細記錄每一條訊息，不做傳入模型用\n",
    "        self.DAG = Q_DAG()\n",
    "\n",
    "        # Setup detailed debug logging\n",
    "        logging.basicConfig(filename=debug_log, level=logging.DEBUG,\n",
    "                            format=\"%(asctime)s [%(levelname)s] %(message)s\", encoding=\"utf-8\")\n",
    "        logging.info(\"\\n=== New llama CQ Execution Started ===\\n\")\n",
    "\n",
    "        # Summary log file\n",
    "        self.summary_json = summary_json\n",
    "\n",
    "        # Initialize JSON file if it doesn't exist\n",
    "        if not os.path.exists(self.summary_json):\n",
    "            with open(self.summary_json, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump([], f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    def handle_tool_call(self, tool_call):\n",
    "        \"\"\"Executes the function requested by OpenAI's function calling system.\"\"\"\n",
    "        function_name = tool_call.tool_name\n",
    "\n",
    "        if function_name == \"search\":\n",
    "            query = tool_call.query\n",
    "\n",
    "            logging.info(f\"Executing search for: {query}\")\n",
    "            return \"search\", search(query, max_results=5)\n",
    "\n",
    "        elif function_name == \"summary\":\n",
    "            summary = tool_call.summary\n",
    "\n",
    "            logging.info(f\"summary: {summary}\")\n",
    "            return \"summary\", summary\n",
    "\n",
    "        try:\n",
    "            arguments = json.loads(tool_call.tool_parameters)\n",
    "        except json.JSONDecodeError as e:\n",
    "            logging.warning(f\"JSON Decode Error in tool_call arguments: {e}\")\n",
    "            return \"retry\", None\n",
    "\n",
    "        logging.info(f\"Tool called: {function_name} with args: {arguments}\")\n",
    "\n",
    "        if function_name == \"question_decompose\":\n",
    "            graph_entries = arguments.get(\"graph\", [])\n",
    "            new_ids = []\n",
    "\n",
    "            for entry in graph_entries:\n",
    "                parent_id = entry.get(\"parent_question_id\")\n",
    "                sub_question = entry.get(\"sub_question\")\n",
    "                edge_annotation = entry.get(\"edge_annotation\")\n",
    "\n",
    "                try:\n",
    "                    new_id, status = self.DAG.derive_question(\n",
    "                        new_sub_question=sub_question,\n",
    "                        edge_annotation=edge_annotation,\n",
    "                        parent_id=parent_id\n",
    "                    )\n",
    "                except ValueError as e:\n",
    "                    logging.warning(str(e))\n",
    "                    continue\n",
    "\n",
    "                # 確定新增成功後再做後續\n",
    "                new_ids.append(new_id)\n",
    "\n",
    "                if status == \"new node added\":\n",
    "\n",
    "                    sub_node_info = self.get_sub_node_info(\n",
    "                        root_question=self.DAG.get_node_question(\"Q\"),\n",
    "                        parent_question=self.DAG.get_node_question(parent_id),\n",
    "                        annotation=edge_annotation,\n",
    "                        target_question=sub_question)\n",
    "\n",
    "                    self.DAG.update_node(new_id, sub_node_info)\n",
    "\n",
    "            if not new_ids:\n",
    "                return \"retry\", None\n",
    "\n",
    "            return \"decompose\", self.DAG.export_DAG()\n",
    "\n",
    "        elif function_name == \"update\":\n",
    "            nodes = arguments.get(\"nodes\", [])\n",
    "\n",
    "            for entry in nodes:\n",
    "                question_id = entry.get(\"question_id\")\n",
    "                new_annotation = entry.get(\"new_annotation\")\n",
    "                try:\n",
    "                    self.DAG.update_node(\n",
    "                        node_id=question_id, new_annotation=new_annotation)\n",
    "                except ValueError as e:\n",
    "                    logging.warning(str(e))\n",
    "                    continue\n",
    "\n",
    "            return \"update\", self.DAG.export_DAG()\n",
    "\n",
    "        elif function_name == \"final_answer\":\n",
    "            logging.info(\"Generating final answer...\")\n",
    "            return \"answer\", arguments.get(\"reason\")\n",
    "\n",
    "        else:\n",
    "            logging.warning(f\"Unknown function requested: {function_name}\")\n",
    "            return \"retry\", None\n",
    "\n",
    "    def get_sub_node_info(self, root_question, parent_question, annotation, target_question):\n",
    "        searcher_system_prompt = \"\"\"You are a research assistant in a multi-agent system designed to answer complex and ambiguous questions. Your role is to assist in answering sub-questions by generating search queries and summarizing relevant results.\n",
    "\n",
    "        You will be given:\n",
    "        - A root question: the user's original, high-level question\n",
    "        - A parent sub-question: a more specific inquiry derived from the root\n",
    "        - A target sub-question: the current question to be addressed\n",
    "        - An edge annotation: an explanation of how the target sub-question connects to its parent (i.e. the reasoning for asking it)\n",
    "\n",
    "        Your job consists of two steps:\n",
    "\n",
    "        1. **Query Generation**  \n",
    "        Based on the context (root question, parent question, edge annotation), write the most focused and effective search query to help retrieve useful information to address the target sub-question.  \n",
    "        - You are not merely rewriting the question. You must *interpret* the intent, especially if the edge annotation implies a deeper or more specific angle.\n",
    "        - For example, if the annotation indicates causal reasoning or a historical background is needed, reflect that in your query.\n",
    "\n",
    "        2. **Summary Generation**  \n",
    "        After receiving retrieved results, produce a concise but contextually appropriate summary that helps address the target sub-question.  \n",
    "        - The summary should match the *type of information* implied by the edge annotation.  \n",
    "        - Sometimes this may be a factual list, a comparison, a causal explanation, or a brief definition.  \n",
    "        - Avoid general or vague summaries; tailor the content to the sub-question's intent.\n",
    "\n",
    "        Be flexible: the edge annotation may imply different kinds of answers (e.g. factual, explanatory, evaluative), and your output should reflect that.\n",
    "\n",
    "        Use the available tools:\n",
    "        - `search(query, reason)`: to retrieve relevant information\n",
    "          Example:\n",
    "          ```json\n",
    "          {\n",
    "            \"reason\": \"To answer the question about dark energy, I need to find out who discovered it.\",\n",
    "            \"query\": \"Who discovered dark energy?\"\n",
    "          }\n",
    "           ```\n",
    "        - `summary(text)`: to return your synthesized summary\n",
    "          Example:\n",
    "          ```json\n",
    "          {\n",
    "            \"summary\": \"Dark energy was discovered by astronomer Edwin Hubble in 1929.\"\n",
    "          }\n",
    "          ```\n",
    "        \"\"\"\n",
    "\n",
    "        searcher_conversation = [{\"role\": \"system\", \"content\": searcher_system_prompt},\n",
    "                                 {\"role\": \"user\",\n",
    "                                  \"content\": (\n",
    "                                      f\"Root question: {root_question}\\n\"\n",
    "                                      f\"Parent question: {parent_question}\\n\"\n",
    "                                      f\"Target sub-question: {target_question}\\n\"\n",
    "                                      f\"Edge annotation: {annotation}\"\n",
    "                                  )\n",
    "                                  }]\n",
    "\n",
    "        # search\n",
    "        response = self.searcher.generate_response(\n",
    "            conversations=searcher_conversation, action=\"Search\")\n",
    "\n",
    "        search_result = self.handle_tool_call(response)[1]\n",
    "\n",
    "        assistant_response = {\n",
    "            \"role\": \"assistant\", \"content\": f\"Tool's name:{response.tool_name}\\nreason:{response.reason}\\nquery:{response.query}\"}\n",
    "        searcher_conversation.append(assistant_response)\n",
    "\n",
    "        tool_response = {\"role\": \"user\", \"content\": str(search_result)}\n",
    "        searcher_conversation.append(tool_response)\n",
    "\n",
    "        # summary\n",
    "\n",
    "        response = self.searcher.generate_response(\n",
    "            conversations=searcher_conversation, action=\"Summary\")\n",
    "\n",
    "        summary_result = self.handle_tool_call(response)[1]\n",
    "\n",
    "        self.conversation_log.extend([\n",
    "            {\"agent\": \"searcher\", **msg} for msg in searcher_conversation\n",
    "        ])\n",
    "\n",
    "        assistant_response = {\"agent\": \"searcher\", \"role\": \"assistant\",\n",
    "                              \"content\": f\"Tool's name:{response.tool_name}\"}\n",
    "\n",
    "        tool_response = {\"agent\": \"searcher\",\n",
    "                         \"role\": \"user\", \"content\": summary_result}\n",
    "\n",
    "        self.conversation_log.append(assistant_response)\n",
    "        self.conversation_log.append(tool_response)\n",
    "\n",
    "        return summary_result\n",
    "\n",
    "    def final_answer(self):\n",
    "        logging.info(\"Generating final answer...\")\n",
    "\n",
    "        if self.conversation_log[-1][\"content\"] == \"After reflecting, please continue to act.\":\n",
    "            self.planner_conversation[-1][\"content\"] = (\"You have reached the maximum number of rounds of action and you must force a final answer.\\n\\n\"\n",
    "                                                        \"Please organize the information you have gathered and write a complete and comprehensive answer to the original question.\")\n",
    "            self.conversation_log[-1][\"content\"] = (\"You have reached the maximum number of rounds of action and you must force a final answer.\\n\\n\"\n",
    "                                                    \"Please organize the information you have gathered and write a complete and comprehensive answer to the original question.\")\n",
    "        else:\n",
    "            self.planner_conversation[-1][\"content\"] += \"\\n\\n\" + (\"You have reached the maximum number of rounds of action and you must force a final answer.\\n\\n\"\n",
    "                                                                  \"Please organize the information you have gathered and write a complete and comprehensive answer to the original question.\")\n",
    "            self.conversation_log[-1][\"content\"] += \"\\n\\n\" + (\"You have reached the maximum number of rounds of action and you must force a final answer.\\n\\n\"\n",
    "                                                              \"Please organize the information you have gathered and write a complete and comprehensive answer to the original question.\")\n",
    "\n",
    "        response = self.planner.generate_response(\n",
    "            self.planner_conversation, action=\"FA\")\n",
    "\n",
    "        return response.final_answer\n",
    "\n",
    "    def _save_summary(self):\n",
    "        \"\"\"Saves the ReAct session to JSON with ordered retrieved data.\"\"\"\n",
    "        # If file is empty or invalid, initialize as empty list\n",
    "        if not os.path.exists(self.summary_json) or os.stat(self.summary_json).st_size == 0:\n",
    "            data = []\n",
    "        else:\n",
    "            try:\n",
    "                with open(self.summary_json, \"r\", encoding=\"utf-8\") as f:\n",
    "                    data = json.load(f)  # Load existing data\n",
    "            except json.JSONDecodeError:\n",
    "                logging.warning(\"JSON file is corrupted. Resetting to empty.\")\n",
    "                data = []  # Reset JSON if it's corrupted\n",
    "\n",
    "        # 把 message 中任何非可序列化的欄位轉換為字串或 dict\n",
    "        serializable_log = []\n",
    "\n",
    "        for msg in self.conversation_log:\n",
    "            if isinstance(msg, dict):\n",
    "                msg_copy = msg.copy()\n",
    "                if \"tool_calls\" in msg_copy:\n",
    "                    msg_copy[\"tool_calls\"] = [tc.model_dump() if hasattr(tc, \"model_dump\") else str(tc)\n",
    "                                              for tc in msg_copy[\"tool_calls\"]]\n",
    "                serializable_log.append(msg_copy)\n",
    "            else:\n",
    "                serializable_log.append(str(msg))\n",
    "\n",
    "        session_summary = {\n",
    "            \"question\": self.conversation_log[1][\"content\"].replace(\"Question: \", \"\"),\n",
    "            \"conversations\": serializable_log,\n",
    "        }\n",
    "\n",
    "        data.append(session_summary)\n",
    "\n",
    "        with open(self.summary_json, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(data, f, ensure_ascii=False,\n",
    "                      indent=4)  # Save updated data\n",
    "\n",
    "    def run(self, question):\n",
    "        logging.info(f\"Starting new session with question: {question}\")\n",
    "\n",
    "        self.DAG.add_root(question)\n",
    "\n",
    "        user_question = {\"role\": \"user\", \"content\": self.DAG.export_DAG()}\n",
    "\n",
    "        self.planner_conversation.append(user_question)\n",
    "\n",
    "        self.conversation_log = [{\"agent\": \"planner\", **msg}\n",
    "                                 for msg in self.planner_conversation]\n",
    "\n",
    "        turn = 1\n",
    "\n",
    "        while turn <= self.max_turns:\n",
    "            logging.info(f\"Turn {turn}: Planner's action.\")\n",
    "\n",
    "            # 1. Generate Thought + Action\n",
    "            response = self.planner.generate_response(\n",
    "                self.planner_conversation, action=\"TC\")\n",
    "            logging.info(f\"LLM Response:\\n{response}\")\n",
    "\n",
    "            # 2. process agents function call\n",
    "            \n",
    "            # 2.1 record the assistant\n",
    "            assistant_response = {\n",
    "                \"role\": \"assistant\", \"content\": f\"Tool's name:{response.tool_name}\\nTool's parameters:{response.tool_parameters}\"}\n",
    "            self.planner_conversation.append(assistant_response)\n",
    "            self.conversation_log.append(\n",
    "                {**assistant_response, \"agent\": \"planner\"})\n",
    "            \n",
    "            state, feedback = self.handle_tool_call(response)\n",
    "\n",
    "            if state == \"retry\":\n",
    "                logging.warning(f\"Retrying Turn {turn}...\")\n",
    "                turn -= 1\n",
    "                self.planner_conversation.pop()\n",
    "                self.conversation_log.pop()\n",
    "                continue\n",
    "\n",
    "            # 2.2 record the tool\n",
    "\n",
    "            if state == \"decompose\":\n",
    "                logging.info(f\"Graph: {feedback}\")\n",
    "\n",
    "                Critical_Evaluation_request = {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": (\n",
    "                        \"You have just decomposed part of the problem into new sub-questions. Now, take a moment to reflect on your current understanding and planning:\\n\\n\"\n",
    "                        \"1. Have the new sub-questions changed or expanded your understanding of the original question or any part of the problem space?\\n\"\n",
    "                        \"    - If yes, consider using `update()` to revise or refine your current annotations.\\n\\n\"\n",
    "                        \"2. Are there any remaining uncertainties, vague concepts, or areas that seem underdeveloped?\\n\"\n",
    "                        \"    - If yes, you may want to continue decomposing or exploring before concluding.\\n\\n\"\n",
    "                        \"3. If you believe you are ready to answer the original question, pause and verify your confidence:\\n\"\n",
    "                        \"    - Formulate **a few critical questions** that would challenge or test your current answer.\\n\"\n",
    "                        \"    - If your answer still holds after these checks, then proceed with `final_answer()`.\\n\"\n",
    "                        \"    - Otherwise, revise your thinking or explore further as needed.\\n\\n\"\n",
    "                        \"Choose your next tool based on your reflection.\"\n",
    "                    )\n",
    "                }\n",
    "\n",
    "                tool_response = {\"role\": \"user\", \"content\": feedback +\n",
    "                                 '\\n\\n' + Critical_Evaluation_request[\"content\"]}\n",
    "                self.planner_conversation.append(tool_response)\n",
    "                self.conversation_log.append(\n",
    "                    {**tool_response, \"agent\": \"planner\"})\n",
    "\n",
    "                # self.planner_conversation.append(Critical_Evaluation_request)\n",
    "                # self.conversation_log.append(\n",
    "                #     {**Critical_Evaluation_request, \"agent\": \"planner\"})\n",
    "\n",
    "                response = self.planner.generate_response(\n",
    "                    self.planner_conversation, action=\"CE\")\n",
    "\n",
    "                Critical_Evaluation_response = {\n",
    "                    \"role\": \"assistant\", \"content\": response.critical_evaluation}\n",
    "                self.planner_conversation.append(Critical_Evaluation_response)\n",
    "                self.conversation_log.append(\n",
    "                    {**Critical_Evaluation_response, \"agent\": \"planner\"})\n",
    "\n",
    "                continue_request = {\"role\": \"user\", \"content\": (\n",
    "                    \"After reflecting, please continue to act.\")}\n",
    "\n",
    "                self.planner_conversation.append(continue_request)\n",
    "                self.conversation_log.append(\n",
    "                    {**continue_request, \"agent\": \"planner\"})\n",
    "\n",
    "            elif state == \"update\":\n",
    "                logging.info(f\"Graph: {feedback}\")\n",
    "\n",
    "                tool_response = {\"role\": \"user\", \"content\": feedback}\n",
    "                self.planner_conversation.append(tool_response)\n",
    "                self.conversation_log.append(\n",
    "                    {**tool_response, \"agent\": \"planner\"})\n",
    "\n",
    "            elif state == \"answer\":\n",
    "                final_answer_request = {\"role\": \"user\", \"content\": (\n",
    "                    \"Please organize the information you have gathered and write a complete and comprehensive answer to the original question.\")}\n",
    "\n",
    "                tool_response = {\n",
    "                    \"role\": \"user\", \"content\": final_answer_request[\"content\"]}\n",
    "                self.planner_conversation.append(tool_response)\n",
    "                self.conversation_log.append(\n",
    "                    {**tool_response, \"agent\": \"planner\"})\n",
    "\n",
    "                # self.planner_conversation.append(final_answer_request)\n",
    "                # self.conversation_log.append(\n",
    "                #     {**final_answer_request, \"agent\": \"planner\"})\n",
    "\n",
    "                response = self.planner.generate_response(\n",
    "                    self.planner_conversation, action=\"FA\")\n",
    "\n",
    "                logging.info(f\"LLM Response:\\n{response.final_answer}\")\n",
    "\n",
    "                self.conversation_log.append(\n",
    "                    {\"agent\": \"planner\", \"role\": \"assistant\", \"content\": response.final_answer})\n",
    "\n",
    "                self._save_summary()\n",
    "                logging.info(\"Final Answer Reached.\")\n",
    "                return response.final_answer\n",
    "\n",
    "            turn += 1\n",
    "\n",
    "        logging.warning(\"Max turns reached. No definitive answer found.\")\n",
    "        final_answer = self.final_answer()\n",
    "\n",
    "        self.conversation_log.append(\n",
    "            {\"agent\": \"planner\", \"role\": \"assistant\", \"content\": final_answer})\n",
    "\n",
    "        self._save_summary()\n",
    "        return final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing https://www.thoughtco.com/utopian-movements-104221: HTTPSConnectionPool(host='www.thoughtco.com', port=443): Read timed out. (read timeout=5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Utopianism is a complex and multifaceted concept that encompasses a wide range of principles and ideals aimed at creating an idealized society. At its core, utopianism is guided by principles such as criticism, change, and compensation, which serve as a foundation for guiding societal participation toward the realization of an envisioned ideal society. These principles motivate collective efforts and introduce a pathway for participation without requiring specific group affiliation.\\n\\nHistorical examples of utopian societies, such as Brook Farm and the Tolstoy Farm, provide valuable insights into both the potential benefits and drawbacks of implementing utopian ideals. These examples highlight the challenges of reconciling diverse individual wants and expectations within a utopian framework, as well as the tendency for such societies to break down due to differences in background and views among their members.\\n\\nThe potential benefits of a utopian society are rooted in principles of social democracy, emphasizing economic justice, democratic participation, and equality under the law. These benefits include comprehensive access to healthcare, education, and a clean environment, as well as guaranteed basic income, freedom of expression, equal opportunities, peaceful coexistence, and shared responsibility. However, the potential drawbacks of a utopian society include the difficulty in meeting the diverse wants and expectations of its members and the historical tendency for such societies to fail due to differences among members.\\n\\nIn conclusion, utopianism presents a complex array of pros and cons, reflecting both the ideals of creating a perfect society and the challenges inherent in achieving such a vision. By understanding the core principles, historical implementations, potential benefits, and drawbacks of utopianism, we can gain a nuanced appreciation for the complexities and trade-offs involved in pursuing utopian ideals.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planner_system_prompt\n",
    "ms = CQ_Solver_llama(llm=\"llama 3.3 70B\", system_prompt=planner_system_prompt, max_turns=9, debug_log=\"llama_debug.log\", summary_json=\"llama_summary.json\")\n",
    "ms.run(\"pros and cons of utopianism?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jinqi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
