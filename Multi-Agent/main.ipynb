{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# å–å¾—å°ˆæ¡ˆæ ¹ç›®éŒ„ (lib çš„çˆ¶ç›®éŒ„)\n",
    "root_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# å°‡ lib åŠ å…¥ Python æ¨¡çµ„æœå°‹è·¯å¾‘\n",
    "sys.path.append(os.path.join(root_dir, \"lib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import Agent\n",
    "from tools import search\n",
    "import re\n",
    "import logging\n",
    "\n",
    "react_system_prompt = \"\"\"You are an AI Agent based on the ReAct framework, tasked with answering questions through the Observe -> Reason -> Act loop.\n",
    "\n",
    "## **Action Rules**\n",
    "1. **Reason**  \n",
    "   - First, output your thinking process based on the current information, using natural language to explain your reasoning.\n",
    "   \n",
    "2. **Act**  \n",
    "   - Execute available tools using **Python syntax**:\n",
    "   - Actions you can use:\n",
    "     ```python\n",
    "     search(query: str) -> List[Dict]  # Get results through a search engine\n",
    "     final_answer() -> None  # Provide the final answer directly\n",
    "     ```\n",
    "   - Your actions must be written in Python code blocks:\n",
    "     ```python\n",
    "     search(\"What is dark energy?\")\n",
    "     ```\n",
    "\n",
    "## **Observation Rules**\n",
    "- If you receive `<retrieved data>`, it contains search results that you should use for your reasoning.\n",
    "\n",
    "## **Examples**\n",
    "\n",
    "### **Searching for Information**\n",
    "'''\n",
    "...Based on the question, I should first search for \"Who discovered dark energy?\" to get background knowledge.\n",
    "```python\n",
    "search(\"Who discovered dark energy?\")\n",
    "```\n",
    "'''\n",
    "\n",
    "### **Answering After Obtaining Sufficient Information**\n",
    "'''\n",
    "...Based on the retrieved data, I now have enough information to answer the question.\n",
    "\n",
    "```python\n",
    "final_answer()\n",
    "```\n",
    "'''\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReAct:\n",
    "    def __init__(self, llm, system_prompt, max_turns=10, log_file=\"react_debug.log\"):\n",
    "        self.agent = Agent(llm=llm)\n",
    "        self.max_turns = max_turns\n",
    "        self.history = [{\"role\": \"developer\", \"content\": system_prompt}]\n",
    "\n",
    "        # Setup logging\n",
    "        logging.basicConfig(filename=log_file, level=logging.DEBUG,\n",
    "                            format=\"%(asctime)s [%(levelname)s] %(message)s\", encoding=\"utf-8\")\n",
    "        logging.info(\"\\n=== New ReAct Execution Started ===\\n\")\n",
    "\n",
    "    def parse_and_execute(self, llm_output: str):\n",
    "        \"\"\"\n",
    "        Parses the LLM's output and executes the corresponding Python action safely.\n",
    "        \"\"\"\n",
    "        logging.info(f\"LLM Output:\\n{llm_output}\")\n",
    "\n",
    "        match = re.search(r\"```python\\n(.*?)\\n```\", llm_output, re.DOTALL)\n",
    "        if match:\n",
    "            code = match.group(1).strip()\n",
    "            logging.info(f\"Parsed Action:\\n{code}\")\n",
    "\n",
    "            # Match search() or final_answer()\n",
    "            search_match = re.fullmatch(r'search\\(\"([^\"]+)\"\\)', code)\n",
    "            final_match = re.fullmatch(r'final_answer\\(\\)', code)  # Ensure no arguments\n",
    "\n",
    "            if search_match:\n",
    "                query = search_match.group(1).strip()\n",
    "                logging.info(f\"Executing search for: {query}\")\n",
    "                return \"search\", search(query, max_results=5)\n",
    "            elif final_match:\n",
    "                logging.info(\"Triggering final_answer()\")\n",
    "                return \"answer\", self.final_answer()\n",
    "            else:\n",
    "                logging.warning(\"Invalid action format detected. Retrying...\")\n",
    "                return \"retry\", None\n",
    "        else:\n",
    "            logging.warning(\n",
    "                \"No valid Python action found in LLM output. Retrying...\")\n",
    "            return \"retry\", None\n",
    "\n",
    "    def final_answer(self):\n",
    "        \"\"\"\n",
    "        Generates a final answer based on the entire conversation history.\n",
    "        \"\"\"\n",
    "        logging.info(\"Generating final answer...\")\n",
    "\n",
    "        conversations = [\n",
    "            {\"role\": \"developer\", \"content\": \"You are an AI assistant designed to answer human questions. Your task is to strictly adhere to the conversation context and integrate information to respond to inquiries.\"}]\n",
    "        conversations += self.history[1:]\n",
    "        conversations += [{\"role\": \"user\", \"content\": \"Please respond to the question based on the conversation content above.\"}]\n",
    "\n",
    "        response = self.agent.generate_response(conversations)\n",
    "        logging.info(f\"Final Answer: {response}\")\n",
    "        return response\n",
    "\n",
    "    def run(self, question):\n",
    "        \"\"\"\n",
    "        åŸ·è¡Œ ReAct è¿´åœˆï¼š\n",
    "        - ç”¢ç”Ÿ Thought, Action\n",
    "        - åŸ·è¡Œ Action å–å¾— Observation\n",
    "        - æŒçºŒè¿´åœˆç›´åˆ°ç²å¾—ç­”æ¡ˆ\n",
    "        \"\"\"\n",
    "        logging.info(f\"Starting new session with question: {question}\")\n",
    "\n",
    "        self.history.append(\n",
    "            {\"role\": \"user\", \"content\": f\"Question: {question}\"})\n",
    "        conversations = self.history.copy()\n",
    "        turn = 1\n",
    "        while turn <= self.max_turns:\n",
    "            logging.info(f\"Turn {turn}: Generating Thought & Action...\")\n",
    "\n",
    "            # 1. Generate Thought + Action\n",
    "            response = self.agent.generate_response(conversations)\n",
    "            logging.info(f\"LLM Response:\\n{response}\")\n",
    "\n",
    "            # 2. Execute Action\n",
    "            state, feedback = self.parse_and_execute(response)\n",
    "\n",
    "            # 3. Retry if LLM output is invalid\n",
    "            if state == \"retry\":\n",
    "                logging.warning(f\"Retrying Turn {turn}...\")\n",
    "                continue  # Do not increment turn, just retry the step\n",
    "\n",
    "            # 4. Update Conversations\n",
    "            if state == \"search\":\n",
    "                # Append new LLM response and retrieval data\n",
    "                self.history.append({\"role\": \"assistant\", \"content\": response})\n",
    "                search_observation = {\n",
    "                    \"role\": \"user\", \"content\": f\"<retrieved data>\\n{feedback}\\n</retrieved data>\"}\n",
    "\n",
    "                conversations = self.history.copy() + [search_observation]\n",
    "\n",
    "                logging.info(f\"Search Results for Turn {turn}: {feedback}\\n\")\n",
    "\n",
    "            elif state == \"answer\":\n",
    "                logging.info(\"Final Answer Reached.\")\n",
    "                return feedback\n",
    "\n",
    "            else:\n",
    "                logging.error(\"Unexpected action detected. Skipping.\")\n",
    "\n",
    "            turn += 1\n",
    "\n",
    "        logging.warning(\"Max turns reached. No definitive answer found.\")\n",
    "        return self.final_answer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'å»ºç¯‰ç¤¾ï¼ˆbuilding societiesï¼‰å’ŒéŠ€è¡Œï¼ˆbanksï¼‰éƒ½æ˜¯é‡‘èæ©Ÿæ§‹ï¼Œä½†åœ¨å®‰å…¨æ€§æ–¹é¢å­˜åœ¨ä¸€äº›å·®ç•°ã€‚é€šå¸¸ï¼Œå…©è€…éƒ½å—åˆ°é‡‘èç›£ç®¡æ©Ÿæ§‹çš„ç›£ç®¡ï¼Œä»¥ç¢ºä¿å­˜æ¬¾äººçš„è³‡é‡‘å®‰å…¨ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›æ¯”è¼ƒçš„è¦é»ï¼š\\n\\n1. **çµæ§‹å’Œç›®çš„**ï¼šå»ºç¯‰ç¤¾é€šå¸¸æ˜¯ç‚ºäº†æœå‹™æœƒå“¡è€Œè¨­ç«‹çš„ï¼Œä¸»è¦æä¾›æˆ¿è²¸å’Œå„²è“„ç”¢å“ï¼Œè€ŒéŠ€è¡Œå‰‡æ˜¯ç‚ºäº†ç›ˆåˆ©ï¼Œæä¾›æ›´å»£æ³›çš„é‡‘èæœå‹™ã€‚\\n\\n2. **å­˜æ¬¾ä¿è­·**ï¼šåœ¨è¨±å¤šåœ‹å®¶ï¼ŒéŠ€è¡Œå’Œå»ºç¯‰ç¤¾éƒ½åƒåŠ äº†å­˜æ¬¾ä¿è­·è¨ˆåŠƒï¼Œä¾‹å¦‚åœ¨è‹±åœ‹ï¼Œå»ºç¯‰ç¤¾å’ŒéŠ€è¡Œçš„å­˜æ¬¾å‡å—é‡‘èæœå‹™è£œå„Ÿè¨ˆåŠƒï¼ˆFSCSï¼‰çš„ä¿éšœï¼Œæœ€å¤šå¯ä¿è­·æ¯ä½å®¢æˆ¶è‡³Â£85,000ã€‚\\n\\n3. **é¢¨éšªç®¡ç†**ï¼šéŠ€è¡Œå¯èƒ½æœƒåƒèˆ‡æ›´å¤šé«˜é¢¨éšªçš„æŠ•è³‡æ¥­å‹™ï¼Œè€Œå»ºç¯‰ç¤¾çš„æ¥­å‹™æ¨¡å¼é€šå¸¸è¼ƒç‚ºä¿å®ˆï¼Œä¸»è¦é›†ä¸­æ–¼ä½å®…è²¸æ¬¾å’Œå„²è“„ã€‚\\n\\n4. **è³‡æœ¬å……è¶³ç‡**ï¼šå»ºç¯‰ç¤¾å’ŒéŠ€è¡Œéƒ½æœ‰è³‡æœ¬å……è¶³ç‡çš„è¦æ±‚ï¼Œä½†å…·é«”çš„è¦å®šå¯èƒ½æœƒæœ‰æ‰€ä¸åŒï¼Œå½±éŸ¿å…¶è²¡å‹™ç©©å®šæ€§ã€‚\\n\\nç¸½é«”ä¾†èªªï¼Œå“ªä¸€ç¨®æ©Ÿæ§‹æ›´å®‰å…¨å–æ±ºæ–¼å¤šç¨®å› ç´ ï¼ŒåŒ…æ‹¬ç›£ç®¡ç’°å¢ƒã€ç®¡ç†å¯¦è¸åŠå€‹åˆ¥æ©Ÿæ§‹çš„è²¡å‹™å¥åº·ç‹€æ³ã€‚åœ¨é¸æ“‡å­˜æ¬¾æ©Ÿæ§‹æ™‚ï¼Œæœ€å¥½è€ƒæ…®å…¶å…¬å…±è©•ç´šã€è²¡å‹™å ±å‘ŠåŠéå»çš„æ¥­å‹™è¡¨ç¾ã€‚'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "react_agent = ReAct(llm=\"gpt-4o-mini\",\n",
    "                    system_prompt=react_system_prompt, max_turns=10)\n",
    "react_agent.run(question=\"are building societies safer than banks?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tools import search  # Import the search function\n",
    "\n",
    "def parse_and_execute(llm_output: str):\n",
    "    \"\"\"\n",
    "    Parses the LLM's output and executes the corresponding Python action safely.\n",
    "    \"\"\"\n",
    "    match = re.search(r\"```python\\n(.*?)\\n```\", llm_output, re.DOTALL)\n",
    "    if match:\n",
    "        code = match.group(1).strip()  # Extract the Python code\n",
    "        print(f\"ğŸ” Parsed Action:\\n{code}\")\n",
    "\n",
    "        # Match the function call format: `search(\"query\")` or `final_answer(\"answer\")`\n",
    "        search_match = re.match(r'search\\(\"(.+)\"\\)', code)\n",
    "        final_match = re.match(r'final_answer\\(\"(.+)\"\\)', code)\n",
    "\n",
    "        if search_match:\n",
    "            query = search_match.group(1)\n",
    "            return search(query, max_results=10)  # Call the actual search function\n",
    "        elif final_match:\n",
    "            return final_match.group(1)  # Just return the final answer\n",
    "        else:\n",
    "            print(\"âš ï¸ Invalid action format detected.\")\n",
    "            return None\n",
    "    else:\n",
    "        print(\"âš ï¸ No valid Python action found in LLM output.\")\n",
    "        return None\n",
    "\n",
    "test = '''\n",
    "æ ¹æ“šå•é¡Œï¼Œæˆ‘æ‡‰è©²å…ˆæœå°‹ \"Who discovered dark energy?\" ä¾†ç²å–èƒŒæ™¯çŸ¥è­˜ã€‚\n",
    "```python\n",
    "search(\"Who discovered dark energy?\")\n",
    "```\n",
    "'''\n",
    "parse_and_execute(test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jinqi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
