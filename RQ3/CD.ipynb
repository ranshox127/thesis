{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bd083d9",
   "metadata": {},
   "source": [
    "# Induction Phase: Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ab5da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Induction_1_system = \"\"\"You are a skilled evaluator that can analyze instruction prompts and generated responses to identify issues. For context, you will be given a task, an instruction prompt used to complete that task, a response to the task, and the ground truth expected response. Your task is to identify reasons why the response failed to meet the ground truth.\"\"\"\n",
    "Induction_1_user = f\"\"\"The original task is: \"Answer the question: '{question}'\"\n",
    "The instruction prompt used was:\n",
    "'''\n",
    "{instruction_prompt}\n",
    "'''\n",
    "The response generated based on the prompt is:\n",
    "'''\n",
    "{generated_response}\n",
    "'''\n",
    "An example of a correct ground truth is:\n",
    "'''\n",
    "{ground_truth}\n",
    "'''\n",
    "The evaluation result was:\n",
    "'''\n",
    "{evaluation_result}\n",
    "'''\n",
    "Based on the evaluation result and the provided\n",
    "example ground truth, can you identify a list of\n",
    "{n} reasons why the generated response failed?\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7587ae47",
   "metadata": {},
   "source": [
    "# Induction Phase: Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f82693",
   "metadata": {},
   "outputs": [],
   "source": [
    "CQ_SYSTEM_PROMPT = \"\"\"You are a Planner Agent designed to reason through complex, open-ended, or ambiguous questions by constructing, reflecting on, and expanding a directed acyclic graph (DAG) of interrelated sub-questions. Your task is not simply to retrieve answers, but to actively explore the question space, refine your understanding, and make informed decisions about when the original question has been sufficiently addressed.\n",
    "\n",
    "---\n",
    "\n",
    "## Problem Space Representation: The Question DAG\n",
    "\n",
    "The DAG is your evolving internal model of the problem. It represents your reasoning process — how the main question relates to sub-questions, intermediate knowledge, and reflections.\n",
    "Each node contains:\n",
    "- `node_id`: a unique identifier\n",
    "- `question`: a sub-question or original question\n",
    "- `annotation`: your current thoughts, insights, summaries, or hypotheses about that question\n",
    "\n",
    "Each annotation helps build and maintain your internal representation of the problem. For example:\n",
    "- A node’s `annotation` may include:\n",
    "  - A summary of what you currently understand about the question\n",
    "  - A hypothesis or assumption you are testing\n",
    "  - A brief note on what you still need to find out\n",
    "- An `edge_annotation` should briefly explain how the sub-question contributes to answering the parent question — e.g., cause-effect, component, condition, clarification, definition, comparison, or implication.\n",
    "---\n",
    "\n",
    "## Input Format\n",
    "\n",
    "You are always shown the current DAG in JSON format, including all nodes and edges, representing the most up-to-date state of your reasoning process.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Reasoning Guidelines\n",
    "\n",
    "- You cannot delete nodes or edges. Even if a previous path turns out to be incorrect or irrelevant, leave it intact and revise your understanding through `update()`. This mimics how humans preserve earlier lines of thought for traceability, reflection, and learning from missteps.\n",
    "- You are encouraged to **revisit and revise** previous thoughts using `update`, especially as new information or sub-answers emerge.\n",
    "- When decomposing, focus on asking the right questions — use logical, causal, definitional, or investigative angles that deepen your understanding.\n",
    "- When unsure or the question is broad, **start by clarifying or framing the problem**, not jumping to answers.\n",
    "- For vague or ill-defined questions, take initiative to deconstruct ambiguity, identify what is missing, and reframe as needed. You shape the problem space.\n",
    "\n",
    "---\n",
    "\n",
    "## Your Tools\n",
    "\n",
    "You have three core actions to build and navigate the problem space:\n",
    "\n",
    "1. **question_decompose**\n",
    "   Use this to break down a question node into one or more meaningful sub-questions.\n",
    "   - You may decompose multiple nodes at once.\n",
    "   - Specify `parent_question_id`, `sub_question`, and an `edge_annotation` explaining the logical or conceptual relationship.\n",
    "   - Multiple parents pointing to the same sub-question are allowed.\n",
    "   - Keep the graph acyclic.\n",
    "\n",
    "   Example:\n",
    "   ```json\n",
    "   {\n",
    "     \"graph\": [\n",
    "       {\n",
    "         \"parent_question_id\": \"Q\",\n",
    "         \"sub_question\": \"How has telework affected work-life boundaries?\",\n",
    "         \"edge_annotation\": \"Understanding personal impact helps assess broader social shifts.\"\n",
    "       },\n",
    "       {\n",
    "         \"parent_question_id\": \"Q.1\",\n",
    "         \"sub_question\": \"Does telework reinforce or reduce social inequality?\",\n",
    "         \"edge_annotation\": \"Social impact includes distributional effects across groups.\"\n",
    "       }\n",
    "     ]\n",
    "   }\n",
    "    ```\n",
    "\n",
    "2.  **update**\n",
    "    Use this to revise or expand the annotation of existing nodes.\n",
    "    - This reflects new insights, summaries, clarifications, or changes in understanding.\n",
    "    - You are encouraged to use this tool to reflect, correct, or reframe — especially after learning something new.\n",
    "    - This is a key part of your **metacognitive behavior** — thinking about your thinking.\n",
    "    \n",
    "    Example:\n",
    "    ```json\n",
    "    {\n",
    "      \"nodes\": [\n",
    "        {\n",
    "          \"question_id\": \"Q.1\",\n",
    "          \"new_annotation\": \"Workers report blurred boundaries between home and work, leading to both flexibility and stress.\"\n",
    "        },\n",
    "        {\n",
    "          \"question_id\": \"Q.2\",\n",
    "          \"new_annotation\": \"Emerging evidence suggests that higher-income workers benefit more from telework options, widening inequality.\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "    ```\n",
    "\n",
    "3.  **final_answer**\n",
    "    Use this only when you believe the original question has been sufficiently addressed **given the available steps so far**.  \n",
    "    You do not need perfect certainty — you must simply provide a reason why the current DAG gives you enough understanding to form a meaningful answer.\n",
    "    - Provide a justification explaining why you believe your DAG now contains enough understanding.\n",
    "    - Your answer should be clear, comprehensive, and informative—sufficient in length to convey key insights.\n",
    "    - You may use paragraph or bullet point format as appropriate.\n",
    "    - Aim to include key aspects uncovered in the DAG — such as causes, mechanisms, consequences, or trade-offs — without repeating every detail.\n",
    "    \n",
    "    Example:\n",
    "    ```json\n",
    "    {\n",
    "      \"reason\": \"The sub-questions cover key social dimensions — lifestyle, geography, and inequality — and their annotations provide sufficient insight.\",\n",
    "    }\n",
    "    ```\n",
    "\n",
    "---\n",
    "\n",
    "## Metacognitive Expectations\n",
    "\n",
    "This is not a static search task — it is an evolving thinking process.\n",
    "\n",
    "- Use `update()` to **reflect**, summarize new insights, question assumptions, or refine your current framing.\n",
    "- Use `question_decompose()` to **expand the problem space**, identify what needs to be known, or clarify uncertainty.\n",
    "- Use `final_answer()` only when your internal model (the DAG) gives you enough confidence that you can answer well.\n",
    "- At each step, treat the DAG as your evolving internal model of understanding — be thoughtful about how you build it.\n",
    "\n",
    "- When starting from a single root question with no sub-questions yet, you may choose to either:\n",
    "  - Use `update()` to record your initial thoughts, assumptions, or possible lines of inquiry, or\n",
    "  - Use `question_decompose()` to begin breaking down the problem into more specific components.\n",
    "There is no fixed preference — use your best judgment based on the question’s clarity and complexity.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ce1846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Induction_2_system = \"\"\"You are a helpful assistant that can analyze instruction prompts and identify high-level, generalizable concepts that can be added to the prompt to ensure the task is completed successfully. A concept is a general instruction derived or inferred from specific instances or occurrences. Concepts should be general enough to be applicable to a wide range of tasks.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87f1724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"\"\"You have just decomposed part of the problem into new sub-questions. Now, take a moment to reflect on your current understanding and planning:\n",
    "\n",
    "1. Have the new sub-questions changed or expanded your understanding of the original question or any part of the problem space?\n",
    "    - If yes, consider using `update()` to revise or refine your current annotations.\n",
    "\n",
    "2. Are there any remaining uncertainties, vague concepts, or areas that seem underdeveloped?\n",
    "    - If yes, you may want to continue decomposing or exploring before concluding.\n",
    "\n",
    "3. If you believe you are ready to answer the original question, pause and verify your confidence:\n",
    "    - Formulate **a few critical questions** that would challenge or test your current answer.\n",
    "    - If your answer still holds after these checks, then proceed with `final_answer()`.\n",
    "    - Otherwise, revise your thinking or explore further as needed.\n",
    "\n",
    "Choose your next tool based on your reflection.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d936446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input file created: batch_input_induction.jsonl\n",
      "Batch input file uploaded with ID: file-CTAtqBG7WPm3MupvrrMVfJ\n",
      "Batch created with ID: batch_68022eeecb888190ac76b52423e367d7\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def prepare_induction_batch(records, output_batch_file=\"batch_input_induction.jsonl\"):\n",
    "    \"\"\"\n",
    "    使用提供的 records 字典準備 Batch API 的輸入檔案，\n",
    "    用於針對 llama 3.3 70B 模型失敗的 CQ_Solver 案例生成提示。\n",
    "\n",
    "    Args:\n",
    "        records (dict): 包含問題 ID、失敗原因、生成的回應、原始問題和 DAG 的字典。\n",
    "        output_batch_file (str): 輸出 Batch API 輸入檔案名。\n",
    "    \"\"\"\n",
    "    batch_requests = []\n",
    "\n",
    "    for question_id, data in records.items():\n",
    "        generated_response = data.get(\"generated_response\", \"N/A\")\n",
    "        ground_truth = data.get(\"ground_truth\", \"N/A\")\n",
    "        DAG = data.get(\"DAG\", \"N/A\")\n",
    "        failure_reasons = data.get(\"failure_reasons\", \"N/A\")\n",
    "        question = data.get(\"question\", \"N/A\")\n",
    "\n",
    "        if generated_response != \"N/A\" and ground_truth != \"N/A\" and failure_reasons != \"N/A\" and DAG != \"N/A\":\n",
    "            Induction_2_user = f\"\"\"- The original instruction prompt was:\n",
    "'''\n",
    "{CQ_SYSTEM_PROMPT}\n",
    "'''\n",
    "- The question is: '{question}'\n",
    "<AI assistant's answer>\n",
    "{generated_response}\n",
    "<AI assistant's answer>\n",
    "\n",
    "<Reference Answer>\n",
    "{ground_truth}\n",
    "<Reference Answer>\n",
    "\n",
    "- The AI assistant's DAG is:\n",
    "```json\n",
    "{DAG}\n",
    "```\n",
    "- Reasons for the failure include:\n",
    "'''\n",
    "{failure_reasons}\n",
    "'''\n",
    "\n",
    "Can you identify a list of 1~3 concepts that can be added to the prompt to ensure the task as well as related ones passes?\"\"\"\n",
    "\n",
    "            batch_requests.append({\n",
    "                \"custom_id\": f\"{question_id}-induction\",\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v1/chat/completions\",\n",
    "                \"body\": {\n",
    "                    \"model\": \"gpt-4o\",\n",
    "                    \"messages\": [{\"role\": \"developer\", \"content\": Induction_2_system},\n",
    "                        {\"role\": \"user\", \"content\": Induction_2_user}],\n",
    "                }\n",
    "            })\n",
    "\n",
    "    # 將請求寫入 Batch 輸入檔案\n",
    "    with open(output_batch_file, 'w') as f:\n",
    "        for req in batch_requests:\n",
    "            f.write(json.dumps(req) + '\\n')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "    batch_requests = []\n",
    "    concepts_union = []\n",
    "    records = {}\n",
    "\n",
    "    # 提取需要處理的記錄\n",
    "    with open(\"../result/final_evaluation_results.jsonl\", \"r\") as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            if data[\"system\"] == \"CQ_Solver\" and data[\"model\"] == \"llama 3.3 70B\" and data[\"score\"][\"Final Score\"] < 8:\n",
    "                records[data[\"question_id\"]] = {\"failure_reasons\": data[\"content\"]}\n",
    "\n",
    "    with open(\"../result/final_experiment_results.jsonl\", \"r\") as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            if data[\"system\"] == \"CQ_Solver\" and data[\"model\"] == \"llama 3.3 70B\" and data[\"question_id\"] in records:\n",
    "                records[data[\"question_id\"]][\"generated_response\"] = data[\"answer\"]\n",
    "                records[data[\"question_id\"]][\"question\"] = data[\"question\"]\n",
    "            elif data[\"system\"] == \"MindSearch\" and data[\"model\"] == \"gpt-4o\" and data[\"question_id\"] in records:\n",
    "                records[data[\"question_id\"]][\"ground_truth\"] = data[\"answer\"]\n",
    "\n",
    "    with open(\"../result/final_llama_CQ_Solver_summary.json\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        question_texts = {record_data[\"question\"] for record_data in records.values() if \"question\" in record_data}\n",
    "        for entry in data:\n",
    "            try:\n",
    "                question_data = json.loads(entry[\"question\"]) # 將 JSON 字串解析為字典\n",
    "                if question_data[\"nodes\"][0][\"question\"] in question_texts:\n",
    "                    # 找到對應的 question_id\n",
    "                    for q_id, record_data in records.items():\n",
    "                        if \"question\" in record_data and record_data[\"question\"] == question_data[\"nodes\"][0][\"question\"]:\n",
    "                            if entry[\"conversations\"][-4][\"content\"] == \"After reflecting, please continue to act.\":\n",
    "                                parts = entry[\"conversations\"][-6][\"content\"].split(suffix)\n",
    "                                if len(parts) == 2:\n",
    "                                    json_str = parts[0].strip()\n",
    "                                    text_part = suffix.strip()\n",
    "                                try:\n",
    "                                    json_data = json.loads(json_str)\n",
    "                                    records[q_id][\"DAG\"] = json_str\n",
    "                                except json.JSONDecodeError as e:\n",
    "                                    print(f\"Error decoding JSON: {e}\")\n",
    "                            else:\n",
    "                                records[q_id][\"DAG\"] = entry[\"conversations\"][-4][\"content\"]\n",
    "                            break # 找到一個就跳出內層迴圈\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON string in summary file: {entry['question']} - {e}\")\n",
    "                continue\n",
    "            except KeyError as e:\n",
    "                print(f\"KeyError accessing summary data: {e} in {entry}\")\n",
    "                continue\n",
    "                    \n",
    "    # for id, data in records.items():\n",
    "    #     print(data[\"DAG\"])\n",
    "\n",
    "    output_batch_file = \"batch_input_induction.jsonl\"\n",
    "    # prepare_induction_batch(records, output_batch_file=output_batch_file)\n",
    "    print(f\"Batch input file created: {output_batch_file}\")\n",
    "\n",
    "    # # 步驟 2: 上傳 Batch 輸入檔案\n",
    "    try:\n",
    "        with open(output_batch_file, \"rb\") as f:\n",
    "            batch_input_file = client.files.create(\n",
    "                file=f,\n",
    "                purpose=\"batch\"\n",
    "            )\n",
    "        print(f\"Batch input file uploaded with ID: {batch_input_file.id}\")\n",
    "        input_file_id = batch_input_file.id\n",
    "\n",
    "        # 步驟 3: 創建 Batch\n",
    "        batch = client.batches.create(\n",
    "            input_file_id=input_file_id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\",\n",
    "            metadata={\"description\": \"Induction batch job for llama 3.3 70B failures\"}\n",
    "        )\n",
    "        print(f\"Batch created with ID: {batch.id}\")\n",
    "\n",
    "        # **後續步驟：輪詢狀態、檢索結果、解析和記錄結果**\n",
    "        # 您需要實現這些步驟，就像之前的流程一樣。\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during Batch API interaction: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccabd409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(id='batch_68022eeecb888190ac76b52423e367d7', completion_window='24h', created_at=1744973550, endpoint='/v1/chat/completions', input_file_id='file-CTAtqBG7WPm3MupvrrMVfJ', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1744973660, error_file_id=None, errors=None, expired_at=None, expires_at=1745059950, failed_at=None, finalizing_at=1744973631, in_progress_at=1744973551, metadata={'description': 'Induction batch job for llama 3.3 70B failures'}, output_file_id='file-CnkfpdVmLBzzJkuqH1yFij', request_counts=BatchRequestCounts(completed=452, failed=0, total=452))\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "batch = client.batches.retrieve(\"batch_68022eeecb888190ac76b52423e367d7\")\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af2468ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "file_response = client.files.content(\"file-CnkfpdVmLBzzJkuqH1yFij\")\n",
    "output_filename = \"concepts_response.jsonl\"\n",
    "with open(output_filename, 'w') as outfile:\n",
    "    outfile.write(file_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28178848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 完成，共處理 452 筆資料。結果已儲存至 concepts_response_clean.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "input_file = \"concepts_response.jsonl\"\n",
    "output_file = \"concepts_response_clean.jsonl\"\n",
    "\n",
    "cleaned_data = []\n",
    "\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            entry = json.loads(line)\n",
    "            custom_id = entry.get(\"custom_id\")\n",
    "            content = (\n",
    "                entry.get(\"response\", {})\n",
    "                     .get(\"body\", {})\n",
    "                     .get(\"choices\", [{}])[0]\n",
    "                     .get(\"message\", {})\n",
    "                     .get(\"content\", \"\")\n",
    "            )\n",
    "            cleaned_data.append({\n",
    "                \"custom_id\": custom_id,\n",
    "                \"content\": content\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 處理失敗: {e}\")\n",
    "            continue\n",
    "\n",
    "# ✅ 可選：寫入清理後的 .jsonl 檔案\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    for item in cleaned_data:\n",
    "        json.dump(item, f, ensure_ascii=False)\n",
    "        f.write('\\n')\n",
    "\n",
    "print(f\"✅ 完成，共處理 {len(cleaned_data)} 筆資料。結果已儲存至 {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9d25016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment 1: 29335 tokens\n",
      "Segment 2: 29402 tokens\n",
      "Segment 3: 29119 tokens\n",
      "Segment 4: 29095 tokens\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "\n",
    "def num_tokens_from_string(string: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "with open(\"concepts_response_clean.jsonl\", 'r', encoding='utf-8') as f:\n",
    "    for i in range(4):  # 假设你想分成 4 个部分\n",
    "        t = 0\n",
    "        start = 0 + 113 * i\n",
    "        end = 113 + 113 * i\n",
    "        \n",
    "        # 重置文件指针到文件开头\n",
    "        f.seek(0)\n",
    "        \n",
    "        for index, line in enumerate(f, start=0):\n",
    "            if start <= index < end:\n",
    "                data = json.loads(line)\n",
    "                t += num_tokens_from_string(data[\"content\"])\n",
    "        \n",
    "        print(f\"Segment {i+1}: {t} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c9dc4f",
   "metadata": {},
   "source": [
    "# Deduction Phase\n",
    "\n",
    "演繹/驗證階段精煉誘發概念 (R)，以盡量減少過度擬合。此階段使用強模型 (Ms) 來分析和驗證任務的誘發概念，然後再將它們導入弱模型 (Mw) 的提示 p。\n",
    "在精煉和驗證誘發概念之後，還會進行一個可選的驗證步驟。\n",
    "\n",
    "在這個步驟中，會從驗證集或使用強模型 (Ms) 合成的範例中選擇與負樣本類似的範例（任務）。\n",
    "然後，將精煉的概念引入弱模型 (Mw) 的提示中，並針對這些類似範例進行測試。\n",
    "此步驟會評估弱模型是否不僅能解決原始錯誤，還能透過達到預先定義的效能臨界值來概括類似案例。\n",
    "只有在達到此臨界值的情況下，精煉的概念才會被接受為最終經提煉概念集 (C) 的一部分。\n",
    "此方法的建議臨界值為 80%，以確保弱模型在原始錯誤（負樣本）和類似範例中都能達到一致的效能改善。\n",
    "\n",
    "在驗證過程中，如果新引入的概念對可測量的效能改善沒有貢獻，那麼它更有可能被捨棄。\n",
    "這可確保只保留有用的概念，有效過濾有害的改進。\n",
    "另一方面，冗餘概念則透過演繹階段提示中提供的指令明確處理，確保語義上相似的概念會被合併或剔除，同時保留概括性。\n",
    "透過結合經驗驗證與結構化篩選機制，此架構可以在不損害有用知識的前提下，最佳化精煉出的概念。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "062422bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Deduction_system = \"\"\"You are an intelligent assistant that processes a list of high-level, generalizable concepts for a given task. Your task is twofold:\n",
    "1. Analyze the list of concepts and remove semantically similar duplicates, ensuring that each remaining concept is unique and distinct.\n",
    "2. Verify that each concept is general enough to be valid for improving the given task. A valid concept should:\n",
    "    - Be generalizable to similar examples within the task.\n",
    "    - Directly address weaknesses or improve performance for the task.\n",
    "A concept is defined as a general instruction derived or inferred from specific instances or occurrences of a task. Your goal is to preserve the clearest, most concise, and generalizable version of each valid concept.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58642847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared batch request for concepts 0 to 112 (113 concepts).\n",
      "Prepared batch request for concepts 113 to 225 (113 concepts).\n",
      "Prepared batch request for concepts 226 to 338 (113 concepts).\n",
      "Prepared batch request for concepts 339 to 451 (113 concepts).\n",
      "All 4 batch requests written to Batch_input_concept_refine.jsonl\n",
      "Batch input file Batch_input_concept_refine.jsonl uploaded with ID: file-V3sYFFAfqQ2LAu9GRDzM1h\n",
      "Batch created with ID: batch_6802a34c8740819088181a0ce35542fb for Batch_input_concept_refine.jsonl\n",
      "Batch input file creation process completed.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "def prepare_deduction_batch_request(concepts_list, i):\n",
    "    \"\"\"\n",
    "    準備 Batch API 的輸入檔案，用於精煉給定的概念列表。\n",
    "\n",
    "    Args:\n",
    "        concepts_list (list): 包含待精煉的概念字串列表。\n",
    "        output_batch_file (str): 輸出 Batch API 輸入檔案名。\n",
    "        cq_system_prompt (str): 規劃代理使用的系統提示。\n",
    "    \"\"\"\n",
    "    concepts_str = \"\\n---\\n\".join(concepts_list)\n",
    "\n",
    "    Deduction_user = f\"\"\"You are given a list of candidate concepts intended to improve the reasoning behavior of a planner agent. The planner operates using the following system prompt:\n",
    "'''\n",
    "{CQ_SYSTEM_PROMPT}\n",
    "'''\n",
    "Your task is to refine the provided concepts list by:\n",
    "1. **Removing duplicates or near-duplicates** (semantically similar or overlapping concepts).\n",
    "2. **Filtering out non-generalizable concepts** that are too specific to a single example or that do not clearly relate to the task defined in the system prompt.\n",
    "3. **Preserving only high-quality, clear, and generalizable concepts** that would help guide the agent’s reasoning across a wide range of complex, open-ended, or ambiguous questions.\n",
    "\n",
    "Here is the original list of concepts to process:\n",
    "{concepts_str}\n",
    "\n",
    "Please return only the **final refined list of unique and valid concepts**, formatted as a bullet point list. Do not include any explanations, metadata, or preambles.\"\"\"\n",
    "\n",
    "    return {\n",
    "        \"custom_id\": f\"concept-refinement-{i}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": \"gpt-4o\",\n",
    "            \"messages\": [{\"role\": \"developer\", \"content\": Deduction_system},\n",
    "                         {\"role\": \"user\", \"content\": Deduction_user}],\n",
    "        }\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    all_concepts = []\n",
    "    num_parts = 4\n",
    "    concepts_per_part = 113 # 大約\n",
    "    output_filename = \"Batch_input_concept_refine.jsonl\"\n",
    "    batch_requests = []\n",
    "\n",
    "    with open(\"concepts_response_clean.jsonl\", 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                if \"content\" in data:\n",
    "                    all_concepts.append(data[\"content\"])\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON line: {line.strip()} - {e}\")\n",
    "                continue\n",
    "\n",
    "    # 將所有概念分成四個部分並準備 Batch API 請求\n",
    "    for i in range(num_parts):\n",
    "        start_index = i * concepts_per_part\n",
    "        end_index = min((i + 1) * concepts_per_part, len(all_concepts))\n",
    "        concepts_part = all_concepts[start_index:end_index]\n",
    "        batch_request = prepare_deduction_batch_request(concepts_part, i+1)\n",
    "        batch_requests.append(batch_request)\n",
    "        print(f\"Prepared batch request for concepts {start_index} to {end_index - 1} ({len(concepts_part)} concepts).\")\n",
    "\n",
    "    # 將所有請求寫入同一個 Batch 輸入檔案\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        for req in batch_requests:\n",
    "            f.write(json.dumps(req) + '\\n')\n",
    "\n",
    "    print(f\"All {len(batch_requests)} batch requests written to {output_filename}\")\n",
    "\n",
    "    # 步驟 2 & 3: 上傳 Batch 輸入檔案並創建 Batch (您可以根據需要取消註釋)\n",
    "    client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "    try:\n",
    "        with open(output_filename, \"rb\") as f:\n",
    "            batch_input_file = client.files.create(\n",
    "                file=f,\n",
    "                purpose=\"batch\"\n",
    "            )\n",
    "        print(f\"Batch input file {output_filename} uploaded with ID: {batch_input_file.id}\")\n",
    "        input_file_id = batch_input_file.id\n",
    "    \n",
    "        batch = client.batches.create(\n",
    "            input_file_id=input_file_id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\",\n",
    "            metadata={\"description\": \"Concept refinement batch job (4 parts)\"}\n",
    "        )\n",
    "        print(f\"Batch created with ID: {batch.id} for {output_filename}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during Batch API interaction for {output_filename}: {e}\")\n",
    "\n",
    "    print(\"Batch input file creation process completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1bb385e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(id='batch_6802a34c8740819088181a0ce35542fb', completion_window='24h', created_at=1745003340, endpoint='/v1/chat/completions', input_file_id='file-V3sYFFAfqQ2LAu9GRDzM1h', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1745003389, error_file_id=None, errors=None, expired_at=None, expires_at=1745089740, failed_at=None, finalizing_at=1745003389, in_progress_at=1745003342, metadata={'description': 'Concept refinement batch job (4 parts)'}, output_file_id='file-RgmgHTApEGrtmV1KinJfTg', request_counts=BatchRequestCounts(completed=4, failed=0, total=4))\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "batch = client.batches.retrieve(\"batch_6802a34c8740819088181a0ce35542fb\")\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "564cce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "file_response = client.files.content(\"file-RgmgHTApEGrtmV1KinJfTg\")\n",
    "output_filename = \"refined_concepts_response.jsonl\"\n",
    "with open(output_filename, 'w') as outfile:\n",
    "    outfile.write(file_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47e23667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 完成，共處理 4 筆資料。結果已儲存至 refined_concepts_response_clean.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "input_file = \"refined_concepts_response.jsonl\"\n",
    "output_file = \"refined_concepts_response_clean.jsonl\"\n",
    "\n",
    "cleaned_data = []\n",
    "\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            entry = json.loads(line)\n",
    "            custom_id = entry.get(\"custom_id\")\n",
    "            content = (\n",
    "                entry.get(\"response\", {})\n",
    "                     .get(\"body\", {})\n",
    "                     .get(\"choices\", [{}])[0]\n",
    "                     .get(\"message\", {})\n",
    "                     .get(\"content\", \"\")\n",
    "            )\n",
    "            cleaned_data.append({\n",
    "                \"custom_id\": custom_id,\n",
    "                \"content\": content\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 處理失敗: {e}\")\n",
    "            continue\n",
    "\n",
    "# ✅ 可選：寫入清理後的 .jsonl 檔案\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    for item in cleaned_data:\n",
    "        json.dump(item, f, ensure_ascii=False)\n",
    "        f.write('\\n')\n",
    "\n",
    "print(f\"✅ 完成，共處理 {len(cleaned_data)} 筆資料。結果已儲存至 {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c761aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Encourage depth and specificity in analysis by incorporating detailed explanations and specific examples.\n",
      "- Emphasize comprehensive coverage of relevant dimensions, such as historical, socio-cultural, economic, and political factors.\n",
      "- Integrate diverse perspectives and interdisciplinary insights for a well-rounded analysis.\n",
      "- Use iterative refinement to expand initial insights and ensure thorough exploration of topics.\n",
      "- Highlight the importance of using concrete examples and evidence to support claims.\n",
      "- Instruct on recognizing and addressing contextual factors for nuanced understanding.\n",
      "- Provide structured and clear organization in responses for coherence and readability.\n",
      "- Ensure a balanced perspective, presenting both positive and negative aspects.\n",
      "- Promote the identification and explanation of specific examples, historical milestones, or events.\n",
      "- Incorporate a structured framework to enhance clarity and logical flow.\n",
      "- Use comparative analysis to provide nuanced insights and depth.\n",
      "- Include practical applications to ground theoretical concepts in real-world scenarios.\n",
      "- Ensure logical integration and synthesis of information for coherent reasoning.\n",
      "- Balance breadth and depth in exploration of topics.\n",
      "- Encourage contextual and structural details in evaluations and responses.\n",
      "- Reflect on broader implications and variability of topics.\n",
      "- Address challenges and reforms within the context.\n",
      "- Incorporate diverse sources and contexts for comprehensive exploration.\n",
      "- Emphasize the importance of contextual relevance and detail.\n",
      "- Utilize scenario creation and hypothetical examples for deeper understanding.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "Deduction_user = f\"\"\"You are given a list of candidate concepts intended to improve the reasoning behavior of a planner agent. The planner operates using the following system prompt:\n",
    "'''\n",
    "{CQ_SYSTEM_PROMPT}\n",
    "'''\n",
    "Your task is to refine the provided concepts list by:\n",
    "1. **Removing duplicates or near-duplicates** (semantically similar or overlapping concepts).\n",
    "2. **Filtering out non-generalizable concepts** that are too specific to a single example or that do not clearly relate to the task defined in the system prompt.\n",
    "3. **Preserving only high-quality, clear, and generalizable concepts** that would help guide the agent’s reasoning across a wide range of complex, open-ended, or ambiguous questions.\n",
    "\n",
    "Here is the original list of concepts to process:\n",
    "'''\n",
    "- Encourage depth and specificity by incorporating detailed explanations, specific examples, and real-world scenarios to improve understanding and engagement.\n",
    "- Emphasize comprehensive coverage of all relevant dimensions, ensuring responses address multiple aspects such as historical, socio-cultural, economic, and political factors.\n",
    "- Guide responses with a structured framework to enhance organization, clarity, and ease of understanding.\n",
    "- Integrate diverse perspectives and interdisciplinary insights to provide a well-rounded and robust analysis.\n",
    "- Focus on balanced perspective, presenting both positive and negative aspects, and exploring interconnectedness to enhance objectivity.\n",
    "- Use iterative refinement to revisit and expand initial insights, ensuring completeness and thorough exploration of topics.\n",
    "- Encourage the use of historical context and specific data to ground arguments and enhance factual robustness.\n",
    "- Highlight the importance of using concrete examples, case studies, and evidence to support claims and enrich understanding.\n",
    "- Instruct on recognizing and addressing contextual factors, including cultural and systemic influences, for more nuanced and comprehensive understanding.\n",
    "\n",
    "---\n",
    "\n",
    "- Encourage the inclusion of specific examples and detailed information relevant to the question.\n",
    "- Emphasize the need for thorough exploration and comprehensive coverage of each aspect.\n",
    "- Ensure the incorporation of diverse perspectives and relevant dimensions related to the main question.\n",
    "- Provide structured and clear organization in responses to enhance readability and coherence.\n",
    "- Highlight the importance of maintaining balance between positive and negative aspects or perspectives.\n",
    "- Include practical applications or case studies to ground theoretical concepts in real-world scenarios.\n",
    "- Instruct the consideration of broader contextual and historical factors that contribute to the current situation.\n",
    "- Promote the identification and explanation of specific examples, historical milestones, or events.\n",
    "- Encourage a balance between depth and breadth, ensuring detailed exploration of key components.\n",
    "- Guide the use of evaluative comparisons or contrasts to provide depth and insights.\n",
    "\n",
    "---\n",
    "\n",
    "- **Incorporate Diverse Perspectives and Factors**: Explore multiple dimensions such as historical, cultural, economic, political, and structural aspects for comprehensive insight.\n",
    "- **Incorporate Specific Examples and Evidence**: Enrich responses with specific examples, studies, or data to enhance depth and credibility.\n",
    "- **Structured Breakdown and Clear Organization**: Organize responses into coherent sections using headings or bullet points for clarity and logical flow.\n",
    "- **Comprehensive Exploration in Context**: Ensure thorough exploration that includes historical, economic, and social contexts relevant to the question.\n",
    "- **Depth and Specificity in Analysis**: Provide detailed explanations for each key aspect, incorporating specific examples and scenarios.\n",
    "- **Balanced Perspective and Detailed Examination**: Provide balanced analysis covering multiple viewpoints and in-depth examination of each dimension.\n",
    "- **Integration of Sub-Topics and Holistic View**: Synthesize insights from various sub-questions for a holistic understanding, integrating different perspectives.\n",
    "- **Consideration of All Relevant Dimensions**: Cover all relevant sub-topics or dimensions comprehensively for a well-rounded analysis.\n",
    "- **Comparative Analysis for Contextual Understanding**: Contrast different perspectives or elements to provide nuanced insights.\n",
    "- **Real-World Examples and Contextual Details**: Include specific historical contexts, events, or legislations to enrich the narrative.\n",
    "- **Inclusion of Historical Context and Key Events**: Provide historical context and reference key events or figures to enhance factuality and completeness.\n",
    "- **Logical Integration and Synthesis of Information**: Ensure logical connections and synthesis of different information pieces for coherent reasoning.\n",
    "- **Breadth and Depth in Exploration**: Balance breadth (wide coverage across topics) and depth (detailed exploration of key aspects).\n",
    "- **Clear Conclusion and Comprehensive Coverage**: Conclude with a synthesis that ties together key insights for a comprehensive understanding.\n",
    "- **Enhance Detail in Descriptive Annotations**: Use detailed annotations in DAGs to guide deeper exploration and reflection.\n",
    "\n",
    "---\n",
    "\n",
    "- Depth and Detail in Decomposition\n",
    "- Integration of Contextual Information\n",
    "- Structured Responses\n",
    "- Emphasize Contextual Depth in Annotations\n",
    "- Incorporate Diverse Perspectives and Implications\n",
    "- Utilize Comparative Analysis for Clarity and Depth\n",
    "- Use of Specific Examples\n",
    "- Comprehensive Scope Exploration\n",
    "- Depth and Specificity in Annotations\n",
    "- Balance Content with Reference Points\n",
    "- In-depth Exploration of All Potential Factors\n",
    "- Contextual and Structural Details\n",
    "- Illustrative Examples and Contextual Clarification\n",
    "- Encourage Contextual and Structural Details\n",
    "- Differentiation Between Support Types\n",
    "- Comprehensive Analysis of Diverse Perspectives\n",
    "- Incorporate Diverse Sources and Contexts\n",
    "- Reflect on Broader Implications\n",
    "- Role Identification and Impact\n",
    "- Address Challenges and Reforms\n",
    "- Holistic Integration and Synthesis\n",
    "- Cross-Validation with External Information\n",
    "- Addressing Systemic and Structural Factors\n",
    "- Explore Broader Implications and Variability\n",
    "- Distinction Between Phases of Development and Maintenance\n",
    "- Dynamic and Continuous Processes\n",
    "- Iterative Reflection and Expansion\n",
    "- Depth of Explanation and Historical Context\n",
    "- Ensure Comprehensive Coverage of Key Aspects\n",
    "- Comparative and Relational Analysis\n",
    "- Detailed Evaluation of Dimensions and Effects\n",
    "- Emphasize Comprehensive Coverage\n",
    "- Balance General and Specific Details\n",
    "- Comprehensive Exploration of Sub-Topics\n",
    "- Emphasize the Importance of Contextual Relevance\n",
    "- Highlight Example-Focused Illustrations\n",
    "- Expand on Practical Applications\n",
    "- Use and Highlight of Structured Analytical Techniques\n",
    "- Path-specific Contributions and Comparisons\n",
    "- Balance Breadth and Depth of Analysis\n",
    "- Integration of Comparative and Evaluative Thinking\n",
    "- In-depth Analysis with Comparative Analysis\n",
    "- Provide Contextual and Detailed Explanations\n",
    "- Iterative Refinement and Comparison\n",
    "- Incorporate Methodological Depth\n",
    "- Multidimensional Analysis\n",
    "- Encourage Contextual Explanation and Evidence\n",
    "- Comparative Analysis for Depth\n",
    "- Scenario Creation for Understanding\n",
    "- Confirm Specificity in Decomposition and Annotation\n",
    "- Comprehensive Framework Construction\n",
    "- Inclusion of Diverse Perspectives and Dimensions\n",
    "- Promote Clarity and Specificity in Decomposition\n",
    "- Structured Breakdown and Comprehensive Exploration\n",
    "'''\n",
    "\n",
    "Please return only the **final refined list of unique and valid concepts**, formatted as a bullet point list. Do not include any explanations, metadata, or preambles.\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[{\"role\": \"developer\", \"content\": Deduction_system},\n",
    "              {\"role\": \"user\", \"content\": Deduction_user}]\n",
    ")\n",
    "\n",
    "with open(\"final_refined_concepts.md\", 'w') as f:\n",
    "    f.write(completion.choices[0].message.content)\n",
    "    \n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856adb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "REFINED_CQ_SYSTEM_PROMPT = \"\"\"You are a Planner Agent designed to reason through complex, open-ended, or ambiguous questions by constructing, reflecting on, and expanding a directed acyclic graph (DAG) of interrelated sub-questions. Your task is not simply to retrieve answers, but to actively explore the question space, refine your understanding, and make informed decisions about when the original question has been sufficiently addressed.\n",
    "\n",
    "---\n",
    "\n",
    "## Problem Space Representation: The Question DAG\n",
    "\n",
    "The DAG is your evolving internal model of the problem. It represents your reasoning process — how the main question relates to sub-questions, intermediate knowledge, and reflections.\n",
    "Each node contains:\n",
    "- `node_id`: a unique identifier\n",
    "- `question`: a sub-question or original question\n",
    "- `annotation`: your current thoughts, insights, summaries, or hypotheses about that question\n",
    "\n",
    "Each annotation helps build and maintain your internal representation of the problem. For example:\n",
    "- A node’s `annotation` may include:\n",
    "  - A summary of what you currently understand about the question\n",
    "  - A hypothesis or assumption you are testing\n",
    "  - A brief note on what you still need to find out\n",
    "- An `edge_annotation` should briefly explain how the sub-question contributes to answering the parent question — e.g., cause-effect, component, condition, clarification, definition, comparison, or implication.\n",
    "---\n",
    "\n",
    "## Input Format\n",
    "\n",
    "You are always shown the current DAG in JSON format, including all nodes and edges, representing the most up-to-date state of your reasoning process.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Reasoning Guidelines\n",
    "\n",
    "- You cannot delete nodes or edges. Even if a previous path turns out to be incorrect or irrelevant, leave it intact and revise your understanding through `update()`. This mimics how humans preserve earlier lines of thought for traceability, reflection, and learning from missteps.\n",
    "- You are encouraged to **revisit and revise** previous thoughts using `update`, especially as new information or sub-answers emerge.\n",
    "- When decomposing, focus on asking the right questions — use logical, causal, definitional, or investigative angles that deepen your understanding.\n",
    "- When unsure or the question is broad, **start by clarifying or framing the problem**, not jumping to answers.\n",
    "- For vague or ill-defined questions, take initiative to deconstruct ambiguity, identify what is missing, and reframe as needed. You shape the problem space.\n",
    "\n",
    "- Encourage depth and specificity in analysis by incorporating detailed explanations and specific examples.\n",
    "- Emphasize comprehensive coverage of relevant dimensions, such as historical, socio-cultural, economic, and political factors.\n",
    "- Integrate diverse perspectives and interdisciplinary insights for a well-rounded analysis.\n",
    "- Use iterative refinement to expand initial insights and ensure thorough exploration of topics.\n",
    "- Highlight the importance of using concrete examples and evidence to support claims.\n",
    "- Instruct on recognizing and addressing contextual factors for nuanced understanding.\n",
    "- Provide structured and clear organization in responses for coherence and readability.\n",
    "- Ensure a balanced perspective, presenting both positive and negative aspects.\n",
    "- Promote the identification and explanation of specific examples, historical milestones, or events.\n",
    "- Incorporate a structured framework to enhance clarity and logical flow.\n",
    "- Use comparative analysis to provide nuanced insights and depth.\n",
    "- Include practical applications to ground theoretical concepts in real-world scenarios.\n",
    "- Ensure logical integration and synthesis of information for coherent reasoning.\n",
    "- Balance breadth and depth in exploration of topics.\n",
    "- Encourage contextual and structural details in evaluations and responses.\n",
    "- Reflect on broader implications and variability of topics.\n",
    "- Address challenges and reforms within the context.\n",
    "- Incorporate diverse sources and contexts for comprehensive exploration.\n",
    "- Emphasize the importance of contextual relevance and detail.\n",
    "- Utilize scenario creation and hypothetical examples for deeper understanding.\n",
    "\n",
    "---\n",
    "\n",
    "## Your Tools\n",
    "\n",
    "You have three core actions to build and navigate the problem space:\n",
    "\n",
    "1. **question_decompose**\n",
    "   Use this to break down a question node into one or more meaningful sub-questions.\n",
    "   - You may decompose multiple nodes at once.\n",
    "   - Specify `parent_question_id`, `sub_question`, and an `edge_annotation` explaining the logical or conceptual relationship.\n",
    "   - Multiple parents pointing to the same sub-question are allowed.\n",
    "   - Keep the graph acyclic.\n",
    "\n",
    "   Example:\n",
    "   ```json\n",
    "   {\n",
    "     \"graph\": [\n",
    "       {\n",
    "         \"parent_question_id\": \"Q\",\n",
    "         \"sub_question\": \"How has telework affected work-life boundaries?\",\n",
    "         \"edge_annotation\": \"Understanding personal impact helps assess broader social shifts.\"\n",
    "       },\n",
    "       {\n",
    "         \"parent_question_id\": \"Q.1\",\n",
    "         \"sub_question\": \"Does telework reinforce or reduce social inequality?\",\n",
    "         \"edge_annotation\": \"Social impact includes distributional effects across groups.\"\n",
    "       }\n",
    "     ]\n",
    "   }\n",
    "    ```\n",
    "\n",
    "2.  **update**\n",
    "    Use this to revise or expand the annotation of existing nodes.\n",
    "    - This reflects new insights, summaries, clarifications, or changes in understanding.\n",
    "    - You are encouraged to use this tool to reflect, correct, or reframe — especially after learning something new.\n",
    "    - This is a key part of your **metacognitive behavior** — thinking about your thinking.\n",
    "    \n",
    "    Example:\n",
    "    ```json\n",
    "    {\n",
    "      \"nodes\": [\n",
    "        {\n",
    "          \"question_id\": \"Q.1\",\n",
    "          \"new_annotation\": \"Workers report blurred boundaries between home and work, leading to both flexibility and stress.\"\n",
    "        },\n",
    "        {\n",
    "          \"question_id\": \"Q.2\",\n",
    "          \"new_annotation\": \"Emerging evidence suggests that higher-income workers benefit more from telework options, widening inequality.\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "    ```\n",
    "\n",
    "3.  **final_answer**\n",
    "    Use this only when you believe the original question has been sufficiently addressed **given the available steps so far**.  \n",
    "    You do not need perfect certainty — you must simply provide a reason why the current DAG gives you enough understanding to form a meaningful answer.\n",
    "    - Provide a justification explaining why you believe your DAG now contains enough understanding.\n",
    "    - Your answer should be clear, comprehensive, and informative—sufficient in length to convey key insights.\n",
    "    - You may use paragraph or bullet point format as appropriate.\n",
    "    - Aim to include key aspects uncovered in the DAG — such as causes, mechanisms, consequences, or trade-offs — without repeating every detail.\n",
    "    \n",
    "    Example:\n",
    "    ```json\n",
    "    {\n",
    "      \"reason\": \"The sub-questions cover key social dimensions — lifestyle, geography, and inequality — and their annotations provide sufficient insight.\",\n",
    "    }\n",
    "    ```\n",
    "\n",
    "---\n",
    "\n",
    "## Metacognitive Expectations\n",
    "\n",
    "This is not a static search task — it is an evolving thinking process.\n",
    "\n",
    "- Use `update()` to **reflect**, summarize new insights, question assumptions, or refine your current framing.\n",
    "- Use `question_decompose()` to **expand the problem space**, identify what needs to be known, or clarify uncertainty.\n",
    "- Use `final_answer()` only when your internal model (the DAG) gives you enough confidence that you can answer well.\n",
    "- At each step, treat the DAG as your evolving internal model of understanding — be thoughtful about how you build it.\n",
    "\n",
    "- When starting from a single root question with no sub-questions yet, you may choose to either:\n",
    "  - Use `update()` to record your initial thoughts, assumptions, or possible lines of inquiry, or\n",
    "  - Use `question_decompose()` to begin breaking down the problem into more specific components.\n",
    "There is no fixed preference — use your best judgment based on the question’s clarity and complexity.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dba9e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for concept in concepts_union:\n",
    "    pass\n",
    "    # validated_concepts = ValidateConcept()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bffb32",
   "metadata": {},
   "source": [
    "# Updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a4ff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Updated_system = f\"\"\"You are a helpful assistant that performs {task}. Follow the given instructions to complete the task successfully\"\"\"\n",
    "Updated_user = f\"\"\"Key concepts to follow: {key_concepts}\n",
    "Instructions: {initial_prompt}\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jinqi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
