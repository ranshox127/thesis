{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# 取得專案根目錄 (lib 的父目錄)\n",
    "root_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# 將 lib 加入 Python 模組搜尋路徑\n",
    "sys.path.append(os.path.join(root_dir, \"lib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import Agent\n",
    "from tools import search\n",
    "import logging\n",
    "\n",
    "react_system_prompt = \"\"\"You are an AI Agent based on the ReAct framework, and your task is to answer questions through the \"observation -> reasoning -> action\" cycle.\n",
    "\n",
    "## **Role and Mission**\n",
    "You are an AI assistant designed to answer human questions. Your task is to strictly adhere to the conversation context and integrate information to respond to inquiries. You must use structured reasoning to determine whether additional information is required before answering.\n",
    "\n",
    "## **Reasoning and Action Rules**\n",
    "1. **Reasoning (Reason)**\n",
    "    - Before taking any action, you must **explain your reasoning**.\n",
    "    - Your reasoning must be concise but informative, summarizing the current situation and justifying the next step.\n",
    "    - If more information is needed, explain why.\n",
    "    - If enough information has been gathered, justify why a final answer can be given.\n",
    "    - **Your reasoning must be included in the `reason` parameter** of the tool call.\n",
    "\n",
    "2. **Action (Act)**\n",
    "    - You have access to the following tools:\n",
    "        - **`search(reason: str, query: str) -> List[Dict]`**\n",
    "            - Use this tool when additional information is needed.\n",
    "            - `reason`: Explain why this search is necessary.\n",
    "            - `query`: The keyword or phrase to search.\n",
    "        - **`final_answer(reason: str) -> str`**\n",
    "            - Use this tool when you have gathered sufficient information to answer the question.\n",
    "            - `reason`: Explain why the current information is sufficient to generate an answer.\n",
    "\n",
    "## **Observation and Response Rules**\n",
    "- You will receive the most recent search result after each action.\n",
    "- You should carefully analyze the new information and decide:\n",
    "    - Whether another search is required?\n",
    "    - Whether you have gathered enough information to generate the final answer?\n",
    "\n",
    "## **Example Usage**\n",
    "\n",
    "### **Using `search` to obtain additional information**\n",
    "'''\n",
    "Based on the question, I need to search for \"Who discovered dark energy?\" to obtain relevant information.\n",
    "'''\n",
    "_(At this point, you should use the `search` tool to perform the search.)_\n",
    "\n",
    "**Correct Tool Call**\n",
    "```json\n",
    "{\n",
    "  \"tool_call\": {\n",
    "    \"name\": \"search\",\n",
    "    \"arguments\": {\n",
    "      \"reason\": \"To answer the question about dark energy, I need to find out who discovered it.\",\n",
    "      \"query\": \"Who discovered dark energy?\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReAct_agent:\n",
    "    def __init__(self, llm, system_prompt, max_turns=9, debug_log=\"react_debug.log\", summary_json=\"react_summary.json\"):\n",
    "        self.agent = Agent(llm=llm)\n",
    "        self.max_turns = max_turns\n",
    "        self.conversation = [{\"role\": \"developer\", \"content\": system_prompt}]\n",
    "        self.conversation_log = []  # 用於詳細記錄每一條訊息，不做傳入模型用\n",
    "        self.total_tokens = []  # 用於詳細記錄每個resopnse的tokens數量\n",
    "\n",
    "        # Setup detailed debug logging\n",
    "        logging.basicConfig(filename=debug_log, level=logging.DEBUG,\n",
    "                            format=\"%(asctime)s [%(levelname)s] %(message)s\", encoding=\"utf-8\")\n",
    "        logging.info(\"\\n=== New ReAct Execution Started ===\\n\")\n",
    "\n",
    "        # Summary log file\n",
    "        self.summary_json = summary_json\n",
    "\n",
    "        # Initialize JSON file if it doesn't exist\n",
    "        if not os.path.exists(self.summary_json):\n",
    "            with open(self.summary_json, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump([], f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        # Define Function Calling Tools\n",
    "        self.tools = [\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"search\",\n",
    "                    \"description\": \"Retrieve relevant web search results for a given query.\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"reason\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"Reason why this search is needed.\"\n",
    "                            },\n",
    "                            \"query\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"Search query string.\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"reason\", \"query\"],\n",
    "                        \"additionalProperties\": False\n",
    "                    },\n",
    "                    \"strict\": True\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"final_answer\",\n",
    "                    \"description\": \"Generate a final answer based on the conversation history.\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"reason\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"Reason why the final answer can now be generated.\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"reason\"],\n",
    "                        \"additionalProperties\": False\n",
    "                    },\n",
    "                    \"strict\": True\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    def handle_tool_call(self, tool_call):\n",
    "        \"\"\"Executes the function requested by OpenAI's function calling system.\"\"\"\n",
    "        function_name = tool_call.function.name\n",
    "        try:\n",
    "            arguments = json.loads(tool_call.function.arguments)\n",
    "        except json.JSONDecodeError as e:\n",
    "            logging.warning(f\"JSON Decode Error in tool_call arguments: {e}\")\n",
    "            return \"retry\", None\n",
    "\n",
    "        logging.info(f\"Tool called: {function_name} with args: {arguments}\")\n",
    "\n",
    "        if function_name == \"search\":\n",
    "            query = arguments.get(\"query\")\n",
    "\n",
    "            if not query:\n",
    "                logging.warning(\n",
    "                    \"Missing 'query' parameter in search function call.\")\n",
    "                return \"retry\", None\n",
    "\n",
    "            logging.info(f\"Executing search for: {query}\")\n",
    "            return \"search\", search(query, max_results=10)\n",
    "\n",
    "        elif function_name == \"final_answer\":\n",
    "            logging.info(\"Generating final answer...\")\n",
    "            return \"answer\", arguments.get(\"reason\")\n",
    "\n",
    "        else:\n",
    "            logging.warning(f\"Unknown function requested: {function_name}\")\n",
    "            return \"retry\", None\n",
    "\n",
    "    def final_answer(self):\n",
    "        \"\"\"\n",
    "        Generates a final answer based on the entire conversation history.\n",
    "        \"\"\"\n",
    "        logging.info(\"Generating final answer...\")\n",
    "\n",
    "        response, usage = self.agent.generate_response(\n",
    "            self.conversation, tools=self.tools, tool_choice={\"type\": \"function\", \"function\": {\"name\": \"final_answer\"}})\n",
    "\n",
    "        assistant_response = {\"agent\": \"planner\", \"role\": \"assistant\",\n",
    "                              \"tool_calls\": response.tool_calls}\n",
    "\n",
    "        self.conversation.append(assistant_response)\n",
    "        self.conversation_log.append(assistant_response)\n",
    "\n",
    "        logging.info(f\"Final Answer: {response.content}\")\n",
    "\n",
    "        self.total_tokens.append({\n",
    "            \"prompt_tokens\": usage.prompt_tokens,\n",
    "            \"completion_tokens\": usage.completion_tokens,\n",
    "            \"total_tokens\": usage.total_tokens\n",
    "        })\n",
    "\n",
    "        tool_call = response.tool_calls[0]\n",
    "        state, feedback = self.handle_tool_call(tool_call)\n",
    "\n",
    "        tool_response = {\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"content\": feedback,\n",
    "        }\n",
    "\n",
    "        self.conversation.append(tool_response)\n",
    "        self.conversation_log.append(tool_response)\n",
    "\n",
    "    def _save_summary(self):\n",
    "        \"\"\"Saves the ReAct session to JSON with ordered retrieved data.\"\"\"\n",
    "\n",
    "        if not os.path.exists(self.summary_json) or os.stat(self.summary_json).st_size == 0:\n",
    "            data = []\n",
    "        else:\n",
    "            try:\n",
    "                with open(self.summary_json, \"r\", encoding=\"utf-8\") as f:\n",
    "                    data = json.load(f)\n",
    "            except json.JSONDecodeError:\n",
    "                logging.warning(\"JSON file is corrupted. Resetting to empty.\")\n",
    "                data = []\n",
    "\n",
    "        # 保證所有 log 可序列化\n",
    "        def make_json_safe(entry):\n",
    "            if isinstance(entry, dict):\n",
    "                safe_entry = entry.copy()\n",
    "                if \"tool_calls\" in safe_entry:\n",
    "                    safe_entry[\"tool_calls\"] = [\n",
    "                        getattr(tc, \"model_dump\", lambda: str(tc))() for tc in safe_entry[\"tool_calls\"]]\n",
    "                return safe_entry\n",
    "            return str(entry)\n",
    "\n",
    "        serializable_log = [make_json_safe(msg)\n",
    "                            for msg in self.conversation_log]\n",
    "\n",
    "        session_summary = {\n",
    "            \"question\": self.conversation_log[1][\"content\"].replace(\"Question: \", \"\"),\n",
    "            \"conversations\": serializable_log,\n",
    "            \"token_usage\": self.total_tokens\n",
    "        }\n",
    "\n",
    "        data.append(session_summary)\n",
    "\n",
    "        with open(self.summary_json, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    def merge_assistant_message(self, conversation, new_message):\n",
    "        \"\"\"\n",
    "        合併 Assistant 的回應，確保不會產生過多獨立的 Assistant 訊息。\n",
    "        \"\"\"\n",
    "        if conversation and conversation[-1][\"role\"] == \"assistant\":\n",
    "            # 直接合併到最後一個 assistant 回應中\n",
    "            conversation[-1][\"content\"] += \"\\n\" + new_message[\"content\"]\n",
    "        else:\n",
    "            conversation.append(new_message)\n",
    "\n",
    "    def run(self, question):\n",
    "        \"\"\"\n",
    "        Executes the ReAct loop:\n",
    "        - Generates Thought, Action\n",
    "        - Executes Action, gets Observation\n",
    "        - Retries if needed\n",
    "        \"\"\"\n",
    "        logging.info(f\"Starting new session with question: {question}\")\n",
    "\n",
    "        user_question = {\"role\": \"user\", \"content\": f\"Question: {question}\"}\n",
    "\n",
    "        self.conversation.append(user_question)\n",
    "\n",
    "        self.conversation_log = self.conversation.copy()\n",
    "\n",
    "        turn = 1\n",
    "\n",
    "        while turn <= self.max_turns:\n",
    "            logging.info(f\"Turn {turn}: Generating Thought & Action...\")\n",
    "\n",
    "            # 1. Generate Thought + Action\n",
    "            response, usage = self.agent.generate_response(\n",
    "                self.conversation, tools=self.tools, tool_choice=\"required\")\n",
    "            logging.info(f\"LLM Response:\\n{response}\")\n",
    "\n",
    "            self.total_tokens.append({\n",
    "                \"prompt_tokens\": usage.prompt_tokens,\n",
    "                \"completion_tokens\": usage.completion_tokens,\n",
    "                \"total_tokens\": usage.total_tokens\n",
    "            })\n",
    "\n",
    "            # 2. Check if the LLM requested a function call\n",
    "            if response.tool_calls:\n",
    "                for tool_call in response.tool_calls:\n",
    "                    state, feedback = self.handle_tool_call(tool_call)\n",
    "\n",
    "                    # 3. Retry if the tool call was invalid\n",
    "                    if state == \"retry\":\n",
    "                        logging.warning(f\"Retrying Turn {turn}...\")\n",
    "                        continue\n",
    "\n",
    "                    assistant_response = {\n",
    "                        \"role\": \"assistant\",\n",
    "                        \"content\": f\"Using tool: {tool_call.function.name} with arguments {tool_call.function.arguments}\",\n",
    "                    }\n",
    "\n",
    "                    self.conversation_log.append(assistant_response)\n",
    "\n",
    "                    # 4. Update Conversations\n",
    "                    if state == \"search\":\n",
    "                        search_observation = {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": f\"<retrieved data>\\n{str(feedback)}\\n</retrieved data>\"\n",
    "                        }\n",
    "\n",
    "                        self.conversation_log.append(search_observation)\n",
    "\n",
    "                        if self.conversation and self.conversation[-1][\"role\"] == \"user\":\n",
    "                            self.conversation.pop()\n",
    "                        self.merge_assistant_message(\n",
    "                            self.conversation, assistant_response)\n",
    "                        self.conversation.append(search_observation)\n",
    "\n",
    "                        logging.info(\n",
    "                            f\"Search Results for Turn {turn}: {feedback}\\n\")\n",
    "\n",
    "                    elif state == \"answer\":\n",
    "                        self.conversation.append(assistant_response)\n",
    "\n",
    "                        final_answer_request = {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": (\n",
    "                                \"Please organize the information you have gathered and write a complete and comprehensive answer to the original question.\")}\n",
    "\n",
    "                        self.conversation.append(final_answer_request)\n",
    "                        self.conversation_log.append(final_answer_request)\n",
    "\n",
    "                        response, usage = self.agent.generate_response(\n",
    "                            self.conversation, tools=self.tools, tool_choice=\"none\")\n",
    "\n",
    "                        logging.info(f\"LLM Response:\\n{response.content}\")\n",
    "\n",
    "                        self.total_tokens.append({\"prompt_tokens\": usage.prompt_tokens,\n",
    "                                                  \"completion_tokens\": usage.completion_tokens,\n",
    "                                                  \"total_tokens\": usage.total_tokens})\n",
    "\n",
    "                        self.conversation_log.append(\n",
    "                            {\"role\": \"assistant\", \"content\": response.content})\n",
    "\n",
    "                        self._save_summary()\n",
    "                        logging.info(\"Final Answer Reached.\")\n",
    "                        return response.content\n",
    "\n",
    "            turn += 1\n",
    "\n",
    "        logging.warning(\"Max turns reached. No definitive answer found.\")\n",
    "        self.final_answer()\n",
    "\n",
    "        final_answer_request = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Please organize the information you have gathered and write a complete and comprehensive answer to the original question.\")}\n",
    "\n",
    "        self.conversation.append(final_answer_request)\n",
    "        self.conversation_log.append(final_answer_request)\n",
    "\n",
    "        response, usage = self.agent.generate_response(\n",
    "            conversations=self.conversation, tools=self.tools, tool_choice=\"none\")\n",
    "\n",
    "        self.total_tokens.append({\"prompt_tokens\": usage.prompt_tokens,\n",
    "                                  \"completion_tokens\": usage.completion_tokens,\n",
    "                                  \"total_tokens\": usage.total_tokens})\n",
    "\n",
    "        self.conversation_log.append(\n",
    "            {\"role\": \"assistant\", \"content\": response.content})\n",
    "\n",
    "        self._save_summary()\n",
    "        return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In 2023, the status of gender inequality globally remains alarming, with reports highlighting significant setbacks and the urgent need for action to achieve gender equality by 2030.\\n\\n1. **Current Trends and Statistics**:\\n   - As per UN Women, progress towards gender equality is deemed \"way off track.\" Currently, only two indicators related to Gender Equality (Goal 5 of the Sustainable Development Goals) are close to target, and none have met their goals. If current trends continue, an estimated 8% of the global female population, equating to approximately 340 million women and girls, will continue to live in extreme poverty by 2030.\\n   - The Global Gender Gap Index 2023 has reported a mere closing of the global gender gap by 68.4%, an improvement of just 0.3 percentage points from the previous year. At this pace, it is projected that full gender parity may take around 134 to 300 years to achieve, depending on the dimension considered (e.g., economic participation could take up to 169 years).\\n   - In terms of economic opportunities, women earn only 51 cents for every dollar earned by men on average, while only 61% of prime working-age women participate in the labor force, significantly lower than men\\'s participation at 90%.\\n\\n2. **Major Hurdles**:\\n   - A lack of women in leadership positions persists, with only 27% of parliamentary seats held by women.\\n   - High rates of poverty and economic opportunity gaps are projected, with around 340 million women and girls expected to live in extreme poverty by 2030. Social protections and access to decent work are critically needed.\\n   - The prevalence of harmful cultural practices such as child marriage continues, with one in five young women married before age 18.\\n   - An urgent funding gap exists for gender equality initiatives, with only about 4% of bilateral aid allocated towards gender equality-related projects, necessitating an additional USD 360 billion annually to make substantial progress.\\n\\n3. **Impact of Climate Change**:\\n   - Climate change is exacerbating gender inequality, with projections indicating that up to 158 million more women and girls could be pushed into poverty due to its adverse effects. Furthermore, food insecurity is anticipated to affect 24% of women and girls by 2030, significantly higher than men.\\n\\n4. **Calls for Action**:\\n   - Leaders, like UN Secretary-General António Guterres, have emphasized the need for immediate, collective action to prevent the erosion of women\\'s rights and to prioritize gender equality as a crucial element in achieving all Sustainable Development Goals. This includes greater investment in women\\'s education, health care, and participation in political and economic spheres.\\n\\nIn summary, the data underscores a critical juncture in addressing gender inequality, with multiple interconnected issues causing setbacks globally. The situation demands urgent, coordinated efforts to close existing gaps and empower women and girls for a just and equitable future.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "react_agent = ReAct_agent(llm=\"gpt-4o-mini\",\n",
    "                    system_prompt=react_system_prompt, max_turns=9)\n",
    "react_agent.run(question=\"is gender inequality still a problem?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jinqi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
