{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# 取得專案根目錄 (lib 的父目錄)\n",
    "root_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# 將 lib 加入 Python 模組搜尋路徑\n",
    "sys.path.append(os.path.join(root_dir, \"lib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import Agent\n",
    "from tools import search\n",
    "import logging\n",
    "\n",
    "react_system_prompt = \"\"\"You are an AI Agent based on the ReAct framework, and your task is to answer questions through the \"observation -> reasoning -> action\" cycle.\n",
    "\n",
    "## **Reasoning and Action Rules**\n",
    "1. **Reasoning (Reason)**\n",
    "    - You should think about why you are performing an action before each action.\n",
    "    - You should make a brief summary of the current situation and decide what to do next.\n",
    "    - Your reasoning should be based on existing information and clearly explain why this is the best next step.\n",
    "    - Your reasoning should be embedded in the `reason` parameter and executed within the `search` or `final_answer` tools.  \n",
    "\n",
    "2. **Action (Act)**\n",
    "    - You **cannot simply respond with text**, but must **use Function Calling to perform actions**.\n",
    "    - You have the following tools available:\n",
    "        - **`search(reason: str, query: str) -> List[Dict]`**\n",
    "            - Use the `search` tool when you need additional information.\n",
    "            - The `reason` parameter should explain why this search is necessary.\n",
    "            - The `query` parameter is the keyword you want to search for.\n",
    "        - **`final_answer(reason: str) -> str`**\n",
    "            - Use the `final_answer` tool when you have collected enough information to answer the question.\n",
    "            - The `reason` parameter should explain why you believe the current information is sufficient to answer the question.\n",
    "\n",
    "## **Observation and Response Rules**\n",
    "- You will receive the last search result each time, and you need to update your reasoning based on this information.\n",
    "- You should analyze this information and decide:\n",
    "    - Whether further search is needed?\n",
    "    - Whether there is enough information to answer the question?\n",
    "\n",
    "## **Example**\n",
    "\n",
    "### **Using `search` to obtain additional information**\n",
    "'''\n",
    "Based on the question, I need to search \"Who discovered dark energy?\" to obtain background knowledge.\n",
    "'''\n",
    "_(At this point, you should use the `search` tool to perform the search)_\n",
    "\n",
    "**Correct Usage**\n",
    "```json\n",
    "{\n",
    "    \"tool_call\": {\n",
    "        \"name\": \"search\",\n",
    "        \"arguments\": {\n",
    "            \"reason\": \"Based on the question, I need to search 'Who discovered dark energy?' to obtain background knowledge.\",\n",
    "            \"query\": \"Who discovered dark energy?\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "### Using final_answer to provide the final answer\n",
    "'''\n",
    "Based on all the information collected, I can now answer the question.\n",
    "'''\n",
    "_(At this point, you should use the final_answer tool to respond)_\n",
    "\n",
    "**Correct Usage**\n",
    "```json\n",
    "{\n",
    "  \"tool_call\": {\n",
    "    \"name\": \"final_answer\",\n",
    "    \"arguments\": {\n",
    "      \"reason\": \"Based on all the information collected, I can now answer the question.\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReAct_agent:\n",
    "    def __init__(self, llm, system_prompt, max_turns=10, debug_log=\"react_debug.log\", summary_json=\"react_summary.json\"):\n",
    "        self.agent = Agent(llm=llm)\n",
    "        self.max_turns = max_turns\n",
    "        self.history = [{\"role\": \"developer\", \"content\": system_prompt}]\n",
    "        self.conversation_log = []\n",
    "        self.total_tokens = []\n",
    "\n",
    "        # Setup detailed debug logging\n",
    "        logging.basicConfig(filename=debug_log, level=logging.DEBUG,\n",
    "                            format=\"%(asctime)s [%(levelname)s] %(message)s\", encoding=\"utf-8\")\n",
    "        logging.info(\"\\n=== New ReAct Execution Started ===\\n\")\n",
    "\n",
    "        # Summary log file\n",
    "        self.summary_json = summary_json\n",
    "\n",
    "        # Initialize JSON file if it doesn't exist\n",
    "        if not os.path.exists(self.summary_json):\n",
    "            with open(self.summary_json, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump([], f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        # Define Function Calling Tools\n",
    "        self.tools = [{\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"search\",\n",
    "                \"description\": \"Retrieve relevant web search results for a given query.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"reason\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Reason why this search is needed.\"\n",
    "                        },\n",
    "                        \"query\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Search query string.\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"reason\", \"query\"]\n",
    "                }\n",
    "            }\n",
    "        }, {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"final_answer\",\n",
    "                \"description\": \"Generate a final answer based on the conversation history.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"reason\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Reason why the final answer can now be generated.\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"reason\"]\n",
    "                }\n",
    "            }\n",
    "        }]\n",
    "\n",
    "    def handle_tool_call(self, tool_call):\n",
    "        \"\"\"Executes the function requested by OpenAI's function calling system.\"\"\"\n",
    "        function_name = tool_call.function.name\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "\n",
    "        logging.info(f\"Tool called: {function_name} with args: {arguments}\")\n",
    "\n",
    "        if function_name == \"search\":\n",
    "            query = arguments[\"query\"]  # 只傳遞 query\n",
    "            logging.info(f\"Executing search for: {query}\")\n",
    "            return \"search\", search(query, max_results=5)\n",
    "\n",
    "        elif function_name == \"final_answer\":\n",
    "            logging.info(\"Generating final answer...\")\n",
    "            return \"answer\", self.final_answer()\n",
    "\n",
    "        else:\n",
    "            logging.warning(f\"Unknown function requested: {function_name}\")\n",
    "            return \"retry\", None\n",
    "\n",
    "    def final_answer(self):\n",
    "        \"\"\"\n",
    "        Generates a final answer based on the entire conversation history.\n",
    "        \"\"\"\n",
    "        logging.info(\"Generating final answer...\")\n",
    "\n",
    "        conversations = [\n",
    "            {\"role\": \"developer\", \"content\": \"You are an AI assistant designed to answer human questions. Your task is to strictly adhere to the conversation context and integrate information to respond to inquiries.\"}]\n",
    "        conversations += self.history[1:]\n",
    "        conversations += [{\"role\": \"user\",\n",
    "                           \"content\": \"Please respond to the question based on the conversation content above.\"}]\n",
    "\n",
    "        response, usage = self.agent.generate_response(\n",
    "            conversations, tools=None, tool_choice=None)\n",
    "\n",
    "        # Append final answer to history\n",
    "        self.conversation_log.append(\n",
    "            {\"role\": \"assistant\", \"content\": response.content})\n",
    "\n",
    "        logging.info(f\"Final Answer: {response.content}\")\n",
    "\n",
    "        self.total_tokens.append({\n",
    "            \"prompt_tokens\": usage.prompt_tokens,\n",
    "            \"completion_tokens\": usage.completion_tokens,\n",
    "            \"total_tokens\": usage.total_tokens\n",
    "        })\n",
    "\n",
    "        self._save_summary()\n",
    "\n",
    "        return response.content\n",
    "\n",
    "    def _save_summary(self):\n",
    "        \"\"\"Saves the ReAct session to JSON with ordered retrieved data.\"\"\"\n",
    "        # If file is empty or invalid, initialize as empty list\n",
    "        if not os.path.exists(self.summary_json) or os.stat(self.summary_json).st_size == 0:\n",
    "            data = []\n",
    "        else:\n",
    "            try:\n",
    "                with open(self.summary_json, \"r\", encoding=\"utf-8\") as f:\n",
    "                    data = json.load(f)  # Load existing data\n",
    "            except json.JSONDecodeError:\n",
    "                logging.warning(\"JSON file is corrupted. Resetting to empty.\")\n",
    "                data = []  # Reset JSON if it's corrupted\n",
    "\n",
    "        session_summary = {\n",
    "            \"question\": self.history[1][\"content\"].replace(\"Question: \", \"\"),\n",
    "            \"conversations\": self.conversation_log,\n",
    "            \"token_usage\": self.total_tokens\n",
    "        }\n",
    "\n",
    "        data.append(session_summary)\n",
    "\n",
    "        with open(self.summary_json, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(data, f, ensure_ascii=False,\n",
    "                      indent=4)  # Save updated data\n",
    "\n",
    "    def run(self, question):\n",
    "        \"\"\"\n",
    "        Executes the ReAct loop:\n",
    "        - Generates Thought, Action\n",
    "        - Executes Action, gets Observation\n",
    "        - Retries if needed\n",
    "        \"\"\"\n",
    "        logging.info(f\"Starting new session with question: {question}\")\n",
    "\n",
    "        user_question = {\"role\": \"user\", \"content\": f\"Question: {question}\"}\n",
    "\n",
    "        self.history.append(user_question)\n",
    "        self.conversation_log.append(user_question)\n",
    "\n",
    "        conversations = self.history.copy()\n",
    "        turn = 1\n",
    "\n",
    "        while turn <= self.max_turns:\n",
    "            logging.info(f\"Turn {turn}: Generating Thought & Action...\")\n",
    "\n",
    "            # 1. Generate Thought + Action\n",
    "            response, usage = self.agent.generate_response(\n",
    "                conversations, tools=self.tools, tool_choice=\"required\")\n",
    "            logging.info(f\"LLM Response:\\n{response}\")\n",
    "\n",
    "            self.total_tokens.append({\n",
    "                \"prompt_tokens\": usage.prompt_tokens,\n",
    "                \"completion_tokens\": usage.completion_tokens,\n",
    "                \"total_tokens\": usage.total_tokens\n",
    "            })\n",
    "\n",
    "            # 2. Check if the LLM requested a function call\n",
    "            if response.tool_calls:\n",
    "                for tool_call in response.tool_calls:\n",
    "                    state, feedback = self.handle_tool_call(tool_call)\n",
    "\n",
    "                    # 3. Retry if the tool call was invalid\n",
    "                    if state == \"retry\":\n",
    "                        logging.warning(f\"Retrying Turn {turn}...\")\n",
    "                        continue\n",
    "\n",
    "                    # 4. Update Conversations\n",
    "                    if state == \"search\":\n",
    "                        assistant_response = {\n",
    "                            \"role\": \"assistant\",\n",
    "                            \"content\": f\"Using tool: {tool_call.function.name} with arguments {tool_call.function.arguments}\",  # ✅ 直接當作回應\n",
    "                        }\n",
    "                        search_observation = {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": f\"<retrieved data>\\n{str(feedback)}\\n</retrieved data>\"  # ✅ 確保是字串\n",
    "                        }\n",
    "\n",
    "                        # Append both LLM response and retrieved data in order\n",
    "                        self.history.append(assistant_response)\n",
    "                        self.conversation_log.append(assistant_response)\n",
    "                        self.conversation_log.append(search_observation)\n",
    "\n",
    "                        conversations = self.history.copy() + \\\n",
    "                            [search_observation]\n",
    "\n",
    "                        logging.info(\n",
    "                            f\"Search Results for Turn {turn}: {feedback}\\n\")\n",
    "\n",
    "                    elif state == \"answer\":\n",
    "                        logging.info(\"Final Answer Reached.\")\n",
    "                        return feedback\n",
    "\n",
    "            turn += 1\n",
    "\n",
    "        logging.warning(\"Max turns reached. No definitive answer found.\")\n",
    "        return self.final_answer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "react_agent = ReAct_agent(llm=\"gpt-4o-mini\",\n",
    "                    system_prompt=react_system_prompt, max_turns=10)\n",
    "react_agent.run(question=\"are building societies safer than banks?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jinqi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
