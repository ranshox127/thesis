{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from agent import Agent\n",
    "load_dotenv()\n",
    "\n",
    "react = Agent(llm=\"gpt-4o-mini\", system_prompt=\"I am a helpful AI assistant.\")\n",
    "# react = Agent(llm=\"llama 3.3 70B\", system_prompt=\"I am a helpful AI assistant.\")\n",
    "response = react.generate_response(prompt=\"What is the capital of Taiwan?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import search\n",
    "\n",
    "results = search(\"the cause of climate change\", max_results=20)\n",
    "\n",
    "print(results)\n",
    "\n",
    "def fa(reason: str, answer: str) -> str:\n",
    "    return answer\n",
    "\n",
    "fa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義 GPT-4o 的價格（每 100 萬 tokens）\n",
    "PRICE_INPUT = 0.59  # USD per 1M tokens\n",
    "PRICE_OUTPUT = 0.79  # USD per 1M tokens\n",
    "\n",
    "# 提供的 token usage 數據\n",
    "token_usage_data = [\n",
    "    {\"prompt_tokens\": 673, \"completion_tokens\": 45},\n",
    "    {\"prompt_tokens\": 20000, \"completion_tokens\": 196},\n",
    "    {\"prompt_tokens\": 109, \"completion_tokens\": 137},\n",
    "\n",
    "    {\"prompt_tokens\": 739, \"completion_tokens\": 54},\n",
    "    {\"prompt_tokens\": 20000, \"completion_tokens\": 106},\n",
    "    {\"prompt_tokens\": 184, \"completion_tokens\": 324},\n",
    "\n",
    "    {\"prompt_tokens\": 813, \"completion_tokens\": 57},\n",
    "    {\"prompt_tokens\": 20000, \"completion_tokens\": 155},\n",
    "    {\"prompt_tokens\": 261, \"completion_tokens\": 77},\n",
    "\n",
    "    {\"prompt_tokens\": 884, \"completion_tokens\": 59},\n",
    "    {\"prompt_tokens\": 20000, \"completion_tokens\": 134},\n",
    "    {\"prompt_tokens\": 334, \"completion_tokens\": 77},\n",
    "\n",
    "    {\"prompt_tokens\": 675, \"completion_tokens\": 49},\n",
    "    {\"prompt_tokens\": 20000, \"completion_tokens\": 73},\n",
    "    {\"prompt_tokens\": 115, \"completion_tokens\": 260},\n",
    "]\n",
    "\n",
    "# 計算平均 input tokens 和 output tokens\n",
    "avg_input_tokens = sum(item[\"prompt_tokens\"] for item in token_usage_data) / 5\n",
    "avg_output_tokens = sum(item[\"completion_tokens\"] for item in token_usage_data) / 5\n",
    "\n",
    "# 進行 500 次運行的總 token 數\n",
    "total_input_tokens = avg_input_tokens * 500\n",
    "total_output_tokens = avg_output_tokens * 500\n",
    "\n",
    "# 計算費用\n",
    "cost_input = (total_input_tokens / 1_000_000) * PRICE_INPUT\n",
    "cost_output = (total_output_tokens / 1_000_000) * PRICE_OUTPUT\n",
    "total_cost = cost_input + cost_output\n",
    "\n",
    "# 顯示計算結果\n",
    "total_input_tokens, total_output_tokens, cost_input, cost_output, total_cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import Agent\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "react_system_prompt = \"\"\"You are an AI Agent based on the ReAct framework, tasked with answering questions through the Observe -> Reason -> Act loop.\n",
    "\n",
    "## **Action Rules**\n",
    "1. **Reason**  \n",
    "   - First, think about the question logically using available information.  \n",
    "   - Explain your reasoning in natural language before taking action.  \n",
    "\n",
    "2. **Act**  \n",
    "   - If more information is needed, use the **search tool** to retrieve relevant information.  \n",
    "   - If enough information has been gathered, use the **final_answer tool** to generate the final response.  \n",
    "\n",
    "### **Available Tools**\n",
    "- `search(query: str) -> List[Dict]`  \n",
    "  - Use this tool when additional information is needed.  \n",
    "  - Example: _\"I should search for 'Who discovered dark energy?' to find relevant information.\"_\n",
    "\n",
    "- `final_answer() -> str`  \n",
    "  - Use this tool when you have gathered enough information to provide a final answer.  \n",
    "  - Example: _\"I now have enough information to answer the question.\"_\n",
    "\n",
    "## **Observation Rules**\n",
    "- When you receive `<retrieved data>`, it contains search results.  \n",
    "- Use these search results to improve your reasoning before taking further action.\n",
    "\n",
    "## **Examples**\n",
    "\n",
    "### **Searching for Information**\n",
    "'''\n",
    "Based on the question, I need to search for \"Who discovered dark energy?\" to get background knowledge.\n",
    "'''\n",
    "_(You should use the `search` tool in this case.)_\n",
    "\n",
    "### **Answering After Obtaining Sufficient Information**\n",
    "'''\n",
    "Based on the retrieved data, I now have enough information to answer the question.\n",
    "'''\n",
    "_(You should use the `final_answer` tool in this case.)_\n",
    "\"\"\"\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search\",\n",
    "            \"description\": \"Retrieve relevant web search results for a given query.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Search query string.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\n",
    "                    \"query\"\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }, {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"final_answer\",\n",
    "            \"description\": \"Generate a final answer based on the conversation history.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "p = [{\"role\": \"system\", \"content\": react_system_prompt},\n",
    "     {\"role\": \"user\", \"content\": f\"how did people prepare for typhoon haiyan\"}\n",
    "     ]\n",
    "\n",
    "# messages + conversations\n",
    "\n",
    "ag = Agent(llm=\"llama 3.3 70B\")\n",
    "message = ag.generate_response(conversations=p, tools=tools)\n",
    "print(message.content)\n",
    "print(\"---\")\n",
    "print(message.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import Agent\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "react_system_prompt = \"\"\"You are an AI Agent based on the ReAct framework, tasked with answering questions through the Observe -> Reason -> Act loop.\n",
    "\n",
    "## **Action Rules**\n",
    "1. **Reason**  \n",
    "   - First, think about the question logically using available information.  \n",
    "   - Explain your reasoning in natural language before taking action.  \n",
    "\n",
    "2. **Act**  \n",
    "   - If more information is needed, use the **search tool** to retrieve relevant information.  \n",
    "   - If enough information has been gathered, use the **final_answer tool** to generate the final response.  \n",
    "\n",
    "### **Available Tools**\n",
    "- `search(query: str) -> List[Dict]`  \n",
    "  - Use this tool when additional information is needed.  \n",
    "  - Example: _\"I should search for 'Who discovered dark energy?' to find relevant information.\"_\n",
    "\n",
    "- `final_answer() -> str`  \n",
    "  - Use this tool when you have gathered enough information to provide a final answer.  \n",
    "  - Example: _\"I now have enough information to answer the question.\"_\n",
    "\n",
    "## **Observation Rules**\n",
    "- When you receive `<retrieved data>`, it contains search results.  \n",
    "- Use these search results to improve your reasoning before taking further action.\n",
    "\n",
    "## **Examples**\n",
    "\n",
    "### **Searching for Information**\n",
    "'''\n",
    "Based on the question, I need to search for \"Who discovered dark energy?\" to get background knowledge.\n",
    "'''\n",
    "_(You should use the `search` tool in this case.)_\n",
    "\n",
    "### **Answering After Obtaining Sufficient Information**\n",
    "'''\n",
    "Based on the retrieved data, I now have enough information to answer the question.\n",
    "'''\n",
    "_(You should use the `final_answer` tool in this case.)_\n",
    "\"\"\"\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search\",\n",
    "            \"description\": \"Retrieve relevant web search results for a given query.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Search query string.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\n",
    "                    \"query\"\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }, {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"final_answer\",\n",
    "            \"description\": \"Generate a final answer based on the conversation history.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "p2 = [{\"role\": \"developer\", \"content\": react_system_prompt},\n",
    "     {\"role\": \"user\", \"content\": f\"how did people prepare for typhoon haiyan\"}\n",
    "     ]\n",
    "\n",
    "ag2 = Agent(llm=\"gpt-4o-mini\")\n",
    "message2, usage2 = ag2.generate_response(conversations=p2, tools=tools)\n",
    "print(message2)\n",
    "print(\"---\")\n",
    "print(usage2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(message2.tool_calls[0].function)\n",
    "function_name = message2.tool_calls[0].function.name\n",
    "arguments = json.loads(message2.tool_calls[0].function.arguments)\n",
    "\n",
    "print(function_name)\n",
    "print(arguments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jinqi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
