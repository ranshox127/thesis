{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from agent import Agent\n",
    "load_dotenv()\n",
    "\n",
    "react = Agent(llm=\"gpt-4o-mini\", system_prompt=\"I am a helpful AI assistant.\")\n",
    "# react = Agent(llm=\"llama 3.3 70B\", system_prompt=\"I am a helpful AI assistant.\")\n",
    "response = react.generate_response(prompt=\"What is the capital of Taiwan?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import search\n",
    "\n",
    "results = search(\"128k context window llms?\", max_results=20)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.get_encoding(\"o200k_base\")\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "print(len(enc.encode(str(results[:10]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import Agent\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "react_system_prompt = \"\"\"You are an AI Agent based on the ReAct framework, tasked with answering questions through the Observe -> Reason -> Act loop.\n",
    "\n",
    "## **Action Rules**\n",
    "1. **Reason**  \n",
    "   - First, think about the question logically using available information.  \n",
    "   - Explain your reasoning in natural language before taking action.  \n",
    "\n",
    "2. **Act**  \n",
    "   - If more information is needed, use the **search tool** to retrieve relevant information.  \n",
    "   - If enough information has been gathered, use the **final_answer tool** to generate the final response.  \n",
    "\n",
    "### **Available Tools**\n",
    "- `search(query: str) -> List[Dict]`  \n",
    "  - Use this tool when additional information is needed.  \n",
    "  - Example: _\"I should search for 'Who discovered dark energy?' to find relevant information.\"_\n",
    "\n",
    "- `final_answer() -> str`  \n",
    "  - Use this tool when you have gathered enough information to provide a final answer.  \n",
    "  - Example: _\"I now have enough information to answer the question.\"_\n",
    "\n",
    "## **Observation Rules**\n",
    "- When you receive `<retrieved data>`, it contains search results.  \n",
    "- Use these search results to improve your reasoning before taking further action.\n",
    "\n",
    "## **Examples**\n",
    "\n",
    "### **Searching for Information**\n",
    "'''\n",
    "Based on the question, I need to search for \"Who discovered dark energy?\" to get background knowledge.\n",
    "'''\n",
    "_(You should use the `search` tool in this case.)_\n",
    "\n",
    "### **Answering After Obtaining Sufficient Information**\n",
    "'''\n",
    "Based on the retrieved data, I now have enough information to answer the question.\n",
    "'''\n",
    "_(You should use the `final_answer` tool in this case.)_\n",
    "\"\"\"\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search\",\n",
    "            \"description\": \"Retrieve relevant web search results for a given query.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Search query string.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\n",
    "                    \"query\"\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }, {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"final_answer\",\n",
    "            \"description\": \"Generate a final answer based on the conversation history.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "p = [{\"role\": \"system\", \"content\": react_system_prompt},\n",
    "     {\"role\": \"user\", \"content\": f\"how did people prepare for typhoon haiyan\"}\n",
    "     ]\n",
    "\n",
    "# messages + conversations\n",
    "\n",
    "ag = Agent(llm=\"llama 3.3 70B\")\n",
    "message = ag.generate_response(conversations=p, tools=tools)\n",
    "print(message.content)\n",
    "print(\"---\")\n",
    "print(message.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import Agent\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "react_system_prompt = \"\"\"You are an AI Agent based on the ReAct framework, tasked with answering questions through the Observe -> Reason -> Act loop.\n",
    "\n",
    "## **Action Rules**\n",
    "1. **Reason**  \n",
    "   - First, think about the question logically using available information.  \n",
    "   - Explain your reasoning in natural language before taking action.  \n",
    "\n",
    "2. **Act**  \n",
    "   - If more information is needed, use the **search tool** to retrieve relevant information.  \n",
    "   - If enough information has been gathered, use the **final_answer tool** to generate the final response.  \n",
    "\n",
    "### **Available Tools**\n",
    "- `search(query: str) -> List[Dict]`  \n",
    "  - Use this tool when additional information is needed.  \n",
    "  - Example: _\"I should search for 'Who discovered dark energy?' to find relevant information.\"_\n",
    "\n",
    "- `final_answer() -> str`  \n",
    "  - Use this tool when you have gathered enough information to provide a final answer.  \n",
    "  - Example: _\"I now have enough information to answer the question.\"_\n",
    "\n",
    "## **Observation Rules**\n",
    "- When you receive `<retrieved data>`, it contains search results.  \n",
    "- Use these search results to improve your reasoning before taking further action.\n",
    "\n",
    "## **Examples**\n",
    "\n",
    "### **Searching for Information**\n",
    "'''\n",
    "Based on the question, I need to search for \"Who discovered dark energy?\" to get background knowledge.\n",
    "'''\n",
    "_(You should use the `search` tool in this case.)_\n",
    "\n",
    "### **Answering After Obtaining Sufficient Information**\n",
    "'''\n",
    "Based on the retrieved data, I now have enough information to answer the question.\n",
    "'''\n",
    "_(You should use the `final_answer` tool in this case.)_\n",
    "\"\"\"\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search\",\n",
    "            \"description\": \"Retrieve relevant web search results for a given query.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Search query string.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\n",
    "                    \"query\"\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }, {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"final_answer\",\n",
    "            \"description\": \"Generate a final answer based on the conversation history.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "p2 = [{\"role\": \"developer\", \"content\": react_system_prompt},\n",
    "     {\"role\": \"user\", \"content\": f\"how did people prepare for typhoon haiyan\"}\n",
    "     ]\n",
    "\n",
    "ag2 = Agent(llm=\"gpt-4o-mini\")\n",
    "message2, usage2 = ag2.generate_response(conversations=p2, tools=tools)\n",
    "print(message2)\n",
    "print(\"---\")\n",
    "print(usage2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(message2.tool_calls[0].function)\n",
    "function_name = message2.tool_calls[0].function.name\n",
    "arguments = json.loads(message2.tool_calls[0].function.arguments)\n",
    "\n",
    "print(function_name)\n",
    "print(arguments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jinqi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
